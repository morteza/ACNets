{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACNets: Attentional Control Networks\n",
    "## Hyper-parameters tuning\n",
    "\n",
    "In this notebook, we explore all the possible decisions that can be made when preprocessing and training a classifier for AVGP vs. NVGPs using functional connectivities.\n",
    "\n",
    "Parameter space includes preprocessing steps, connectivity matrices, and hyper-parameters for the classifier. Here are the hyper-parameters that we are exploring:\n",
    "\n",
    "- Preprocessing\n",
    "  - high-pass and low-pass filtering\n",
    "  - parcellation atlases\n",
    "  - binarization\n",
    "  - binarization threshold\n",
    "  - connectivity measures\n",
    "  - diagonal connectivity\n",
    "  - factor analysis\n",
    "  - include only inter-network connectivities/factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn scikit-optimize xarray tqdm factor_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/morteza/workspace/acnets/notebooks/resting_state/1 Hyperparameters Tuning.ipynb Cell 3'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/resting_state/1%20Hyperparameters%20Tuning.ipynb#ch0000002?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskopt\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspace\u001b[39;00m \u001b[39mimport\u001b[39;00m Real, Integer, Categorical\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/resting_state/1%20Hyperparameters%20Tuning.ipynb#ch0000002?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfactor_analyzer\u001b[39;00m \u001b[39mimport\u001b[39;00m ConfirmatoryFactorAnalyzer, ModelSpecificationParser\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/resting_state/1%20Hyperparameters%20Tuning.ipynb#ch0000002?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39macnets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpipeline\u001b[39;00m \u001b[39mimport\u001b[39;00m Parcellation, ConnectivityExtractor\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/resting_state/1%20Hyperparameters%20Tuning.ipynb#ch0000002?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39macnets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpipeline\u001b[39;00m \u001b[39mimport\u001b[39;00m ConnectivityVectorizer\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/resting_state/1%20Hyperparameters%20Tuning.ipynb#ch0000002?line=25'>26</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcopy\u001b[39;00m \u001b[39mimport\u001b[39;00m deepcopy\n",
      "File \u001b[0;32m/acnets/python/acnets/pipeline/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///acnets/python/acnets/pipeline/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparcellation\u001b[39;00m \u001b[39mimport\u001b[39;00m Parcellation\n\u001b[1;32m      <a href='file:///acnets/python/acnets/pipeline/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconnectivity_vectorizer\u001b[39;00m \u001b[39mimport\u001b[39;00m ConnectivityVectorizer\n\u001b[0;32m----> <a href='file:///acnets/python/acnets/pipeline/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconnectivity_extractor\u001b[39;00m \u001b[39mimport\u001b[39;00m ConnectivityExtractor\n\u001b[1;32m      <a href='file:///acnets/python/acnets/pipeline/__init__.py?line=4'>5</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mParcellation\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='file:///acnets/python/acnets/pipeline/__init__.py?line=5'>6</a>\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mConnectivityVectorizer\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='file:///acnets/python/acnets/pipeline/__init__.py?line=6'>7</a>\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mConnectivityExtractor\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='file:///acnets/python/acnets/pipeline/__init__.py?line=7'>8</a>\u001b[0m            ]\n",
      "File \u001b[0;32m/acnets/python/acnets/pipeline/connectivity_extractor.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///acnets/python/acnets/pipeline/connectivity_extractor.py?line=0'>1</a>\u001b[0m \u001b[39m# to extract connectivity from time series\u001b[39;00m\n\u001b[1;32m      <a href='file:///acnets/python/acnets/pipeline/connectivity_extractor.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m TransformerMixin, BaseEstimator\n\u001b[0;32m----> <a href='file:///acnets/python/acnets/pipeline/connectivity_extractor.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnectome\u001b[39;00m \u001b[39mimport\u001b[39;00m ExtraConnectivityMeasure\n\u001b[1;32m      <a href='file:///acnets/python/acnets/pipeline/connectivity_extractor.py?line=6'>7</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mConnectivityExtractor\u001b[39;00m(TransformerMixin, BaseEstimator):\n\u001b[1;32m      <a href='file:///acnets/python/acnets/pipeline/connectivity_extractor.py?line=7'>8</a>\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, kind\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcorrelation\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/acnets/python/acnets/connectome/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='file:///acnets/python/acnets/connectome/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mextra_connectivity_matrices\u001b[39;00m \u001b[39mimport\u001b[39;00m ExtraConnectivityMeasure\n\u001b[1;32m      <a href='file:///acnets/python/acnets/connectome/__init__.py?line=2'>3</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mExtraConnectivityMeasure\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/acnets/python/acnets/connectome/extra_connectivity_matrices.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///acnets/python/acnets/connectome/extra_connectivity_matrices.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnilearn\u001b[39;00m \u001b[39mimport\u001b[39;00m connectome\n\u001b[1;32m      <a href='file:///acnets/python/acnets/connectome/extra_connectivity_matrices.py?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_transfer_entropy\u001b[39;00m \u001b[39mimport\u001b[39;00m transfer_entropy\n\u001b[0;32m----> <a href='file:///acnets/python/acnets/connectome/extra_connectivity_matrices.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_chatterjee\u001b[39;00m \u001b[39mimport\u001b[39;00m chatterjee_xicoef\n\u001b[1;32m      <a href='file:///acnets/python/acnets/connectome/extra_connectivity_matrices.py?line=8'>9</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mExtraConnectivityMeasure\u001b[39;00m(connectome\u001b[39m.\u001b[39mConnectivityMeasure):\n\u001b[1;32m     <a href='file:///acnets/python/acnets/connectome/extra_connectivity_matrices.py?line=10'>11</a>\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, cov_estimator\u001b[39m=\u001b[39mLedoitWolf(store_precision\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m     <a href='file:///acnets/python/acnets/connectome/extra_connectivity_matrices.py?line=11'>12</a>\u001b[0m                kind\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcovariance\u001b[39m\u001b[39m'\u001b[39m, vectorize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, discard_diagonal\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/acnets/python/acnets/connectome/_chatterjee.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///acnets/python/acnets/connectome/_chatterjee.py?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='file:///acnets/python/acnets/connectome/_chatterjee.py?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchatterjee_xicoef\u001b[39m(X: \u001b[39mlist\u001b[39;49m[np\u001b[39m.\u001b[39;49mndarray]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m      <a href='file:///acnets/python/acnets/connectome/_chatterjee.py?line=4'>5</a>\u001b[0m   \u001b[39m\"\"\"Fast Chatterjee Xi correlation coefficient.\u001b[39;00m\n\u001b[1;32m      <a href='file:///acnets/python/acnets/connectome/_chatterjee.py?line=5'>6</a>\u001b[0m \n\u001b[1;32m      <a href='file:///acnets/python/acnets/connectome/_chatterjee.py?line=6'>7</a>\u001b[0m \u001b[39m  References:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///acnets/python/acnets/connectome/_chatterjee.py?line=18'>19</a>\u001b[0m \u001b[39m      Xi matrix of size n_subjects * n_regions * n_regions\u001b[39;00m\n\u001b[1;32m     <a href='file:///acnets/python/acnets/connectome/_chatterjee.py?line=19'>20</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///acnets/python/acnets/connectome/_chatterjee.py?line=21'>22</a>\u001b[0m   X_xi \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set('notebook')\n",
    "\n",
    "from sklearn import preprocessing, model_selection, metrics, ensemble\n",
    "from sklearn import decomposition, cross_decomposition, feature_selection, dummy, svm\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nilearn import datasets as nilean_datasets\n",
    "\n",
    "import skopt\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from factor_analyzer import ConfirmatoryFactorAnalyzer, ModelSpecificationParser\n",
    "\n",
    "from python.acnets.pipeline import Parcellation, ConnectivityExtractor\n",
    "from python.acnets.pipeline import ConnectivityVectorizer\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Technical reproducibility\n",
    "%reload_ext watermark\n",
    "%watermark -iv -co -ituhmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = pd.read_csv('data/julia2018/participants.tsv', sep='\\t')\n",
    "participants = participants.query('preprocessed_rsfmri == True')\n",
    "X = participants['participant_id'].apply(lambda x: x.split('-')[1]).values\n",
    "y = participants['group'].values\n",
    "\n",
    "# X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto-sklearn\n",
    "\n",
    "try:\n",
    "  from autosklearn.experimental.askl2 import AutoSklearn2Classifier\n",
    "\n",
    "  automl = Pipeline([\n",
    "    ('parcellation', Parcellation('dosenbach2010')),\n",
    "    ('extractor', ConnectivityExtractor('partial correlation')),\n",
    "    ('vectorizer', ConnectivityVectorizer(discard_diagonal=True)),\n",
    "    ('zv', feature_selection.VarianceThreshold()),\n",
    "    # ('classifier', svm.SVC(probability=True))\n",
    "    ('classifier', AutoSklearn2Classifier(time_left_for_this_task=30,))\n",
    "  ])\n",
    "\n",
    "  split = model_selection.StratifiedShuffleSplit(n_splits=5, test_size=0.2)\n",
    "  train, test = next(split.split(X, y))\n",
    "\n",
    "  automl.fit(X[train], y[train], X_test=X[test], y_test=y[test])\n",
    "  y_pred = automl.predict(X[test])\n",
    "  print('Accuracy:', metrics.accuracy_score(y[test], y_pred))\n",
    "\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian tuning\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('parcellation', Parcellation()),\n",
    "  ('extractor', ConnectivityExtractor()),\n",
    "  ('vectorizer', ConnectivityVectorizer()),\n",
    "  ('zv', feature_selection.VarianceThreshold()),\n",
    "  ('classifier', svm.SVC(probability=True))\n",
    "])\n",
    "\n",
    "param_space = {\n",
    "  'parcellation__atlas_name': Categorical(\n",
    "    ['dosenbach2007', 'dosenbach2010', 'difumo_64_2mm'],\n",
    "    transform='label'),\n",
    "  'extractor__kind': Categorical(\n",
    "    ['correlation', 'tangent', 'partial correlation'], #'chatterjee'],\n",
    "    transform='label'),\n",
    "  'vectorizer__discard_diagonal': Categorical(\n",
    "    [True, False],\n",
    "    transform='label'),\n",
    "  'classifier__C': Real(1e-3, 1e3, 'log-uniform'),\n",
    "  'classifier__kernel': Categorical(\n",
    "    ['linear', 'rbf'],\n",
    "    transform='label'),\n",
    "}\n",
    "\n",
    "opt_cv = model_selection.StratifiedKFold(5)\n",
    "opt = BayesSearchCV(\n",
    "  pipe, param_space, cv=opt_cv,\n",
    "  # n_jobs=1,\n",
    "  verbose=0,\n",
    "  n_points=2,\n",
    "  n_iter=10,\n",
    "  scoring='accuracy')\n",
    "\n",
    "split = model_selection.StratifiedShuffleSplit(n_splits=10, test_size=0.2)\n",
    "# FIXME DEBUG train, test = next(split.split(X, y))\n",
    "\n",
    "for train, test in split.split(X, y):\n",
    "  progress_bar = tqdm(total=opt.total_iterations)\n",
    "\n",
    "  model = opt.fit(\n",
    "    X[train], y[train],\n",
    "    callback = [\n",
    "      skopt.callbacks.DeadlineStopper(total_time=300),\n",
    "      lambda _: False if progress_bar.update() else False,\n",
    "    ]\n",
    "  )\n",
    "  progress_bar.close()\n",
    "  \n",
    "  print(model.best_estimator_)\n",
    "\n",
    "  train_score = model.score(X[train], y[train])\n",
    "  test_score = model.score(X[test], y[test])\n",
    "  \n",
    "  print(f'Score (train/test): {train_score:.3f}/{test_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "X is a 2D matrix of size (n_subjects, n_features), where features are the connectivity measures, e.g., correlation.\n",
    "\n",
    "We first load the data and preprocess it, i.e., binarize the X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirmatory factor analysis\n",
    "Now, we programmatically define the factor model. Factor model is a dictionary that maps latent factors, i.e., brain networks, to the observable variables, i.e., node features within the brain networks.\n",
    "\n",
    "We then fit the factor model to the data and extract the factor loadings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "factors_model = dict.fromkeys(X.columns.levels[0], [])\n",
    "\n",
    "for k,v in X.columns:\n",
    "  factors_model[k] = factors_model[k] + [v]\n",
    "\n",
    "print('networks:', list(factors_model.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The factor model analyzer uses SciPy optimizer under the hood. It's slow for our data, so we limit the features to those within the networks and discard intra-network connections. This will produce a dataset of 118 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X\n",
    "if FIT_ONLY_INTER_NETWORK_CONNECTIVITIES:\n",
    "  _inter_network_cols = ~X.columns.get_level_values(0).str.contains(\"â†”\")\n",
    "\n",
    "  _control_networks = [\n",
    "    'cerebellum', 'cingulo-opercular', 'fronto-parietal',\n",
    "    'default', 'sensorimotor', 'occipital']\n",
    "\n",
    "  _control_networks_cols = X.columns.get_level_values(0).isin(_control_networks)\n",
    "\n",
    "  X_df = X.loc[:,(_inter_network_cols & _control_networks_cols,)]\n",
    "  \n",
    "  #TODO remove unwanted networks from factors_model\n",
    "  \n",
    "  factors_model = {\n",
    "    k:v for k,v in factors_model.items() if k in X_df.columns.get_level_values(0).unique().to_list()\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of features per network:')\n",
    "{k:len(v) for k,v in factors_model.items()}\n",
    "factors_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Now fitting CFA to our data of size {X_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity, calculate_kmo\n",
    "\n",
    "# Adequacy Test\n",
    "\n",
    "# X_norm = preprocessing.StandardScaler().fit_transform(X_df)\n",
    "\n",
    "chi2_value, chi2_pvalue = calculate_bartlett_sphericity(X_df)\n",
    "kmo_all, kmo_total_score = calculate_kmo(X_df)\n",
    "\n",
    "print(\n",
    "  'chi2 (p-value): {} ({})\\n'\n",
    "  'kmo total score: {}'.format(chi2_value, chi2_pvalue, kmo_total_score)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_spec = ModelSpecificationParser.parse_model_specification_from_dict(X_df, factors_model)\n",
    "\n",
    "\n",
    "cfa = ConfirmatoryFactorAnalyzer(factors_spec, disp=False)\n",
    "\n",
    "X_norm = X_df # DEBUG preprocessing.StandardScaler().fit_transform(X_df)\n",
    "X_cfa = cfa.fit_transform(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Now tuning the classifier for X_cfa of size', X_cfa.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the factor model\n",
    "\n",
    "Extracted latent features can not be used for prediction.\n",
    "\n",
    "The following cell perform a permutation test to contrast observed and random scores (ROC AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.RepeatedStratifiedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "# test/train splits\n",
    "train, test = model_selection.train_test_split(\n",
    "  X_cfa,\n",
    "  test_size=0.2,\n",
    "  shuffle=True,\n",
    "  stratify=y,)\n",
    "\n",
    "\n",
    "# model fitting\n",
    "try:\n",
    "  progress_bar = tqdm(total=opt.total_iterations)\n",
    "  opt.fit(\n",
    "    X_cfa, y,\n",
    "    callback = [\n",
    "      skopt.callbacks.DeadlineStopper(total_time=120),\n",
    "      lambda _: False if progress_bar.update() else False,\n",
    "  ])\n",
    "finally:\n",
    "  progress_bar.clear()\n",
    "  progress_bar.close()\n",
    "\n",
    "\n",
    "# permutation testing\n",
    "obs_score, rnd_scores, obs_pvalue = model_selection.permutation_test_score(\n",
    "  opt.best_estimator_,\n",
    "  X_cfa, y,\n",
    "  cv=cv,\n",
    "  n_permutations=100,\n",
    "  scoring='roc_auc')\n",
    "\n",
    "print('Observed score (p-value): {:.3f} ({:.3f})'.format(obs_score, obs_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = sns.displot(rnd_scores, kde=True)\n",
    "g.set(xlabel='ROC AUC')\n",
    "g.ax.set_title('{} {}'.format(ATLAS, CONNECTIVITY_MEASURE))\n",
    "\n",
    "plt.axvline(obs_score, ls='--', color='blue')\n",
    "\n",
    "\n",
    "plt.text(x=obs_score + .02,\n",
    "        y=plt.gca().get_ylim()[1] * .7,\n",
    "        s=f'AUC = {obs_score:.2f}\\n(p-value: {obs_pvalue:.3f})')\n",
    "\n",
    "plt.suptitle(f'{cv.n_repeats} repeats of 5-fold cross-validated hyper-parameter tuning.\\n'\n",
    "             f'Dashed line is the observed scores without permutation '\n",
    "             f'and blue curves represents $H_0$ (100 permuted y labels)',\n",
    "             y=1.2, x=.08, ha='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.columns.get_level_values(0).unique().to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we visualize the factor loadings against the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_network_names = X_df.columns.get_level_values(0).unique().to_series()\n",
    "# print(_network_names)\n",
    "palt = dict(zip(\n",
    "  _network_names,\n",
    "  sns.color_palette('Set1', len(_network_names))))\n",
    "\n",
    "network_colors = pd.Series(_network_names).apply(lambda x: pd.Series((palt[x], x)))\n",
    "network_colors.rename(columns={0:'color', 1:'network'}, inplace=True)\n",
    "network_colors.reset_index(drop=True, inplace=True)\n",
    "network_colors.drop_duplicates(inplace=True)\n",
    "network_colors.set_index('network', inplace=True)\n",
    "\n",
    "\n",
    "feature_colors = {}\n",
    "for network,regions in factors_model.items():\n",
    "  for region in regions:\n",
    "    feature_colors[region] = network_colors.loc[network, 'color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfa_loadings = pd.DataFrame(\n",
    "  cfa.loadings_,\n",
    "  index=X_df.columns.get_level_values(1),\n",
    "  columns=list(factors_model.keys())\n",
    ")\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(30,3))\n",
    "# sns.heatmap(fa_loadings.T, ax=ax)\n",
    "\n",
    "\n",
    "g = sns.clustermap(cfa_loadings.T, figsize=(25,5),\n",
    "               row_cluster=False, col_cluster=True,\n",
    "               cbar_pos=(.975, .25, 0.005, 0.3),\n",
    "               cmap='RdBu',\n",
    "               xticklabels=1,\n",
    "               colors_ratio=.07,\n",
    "               dendrogram_ratio=.3,\n",
    "               col_colors=list(feature_colors.values()),)\n",
    "\n",
    "g.ax_row_dendrogram.set_visible(False)\n",
    "\n",
    "# to rotate y labels\n",
    "# g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also report the importance of each factor, that is coefficient of the linear SVM classifier we trained above.\n",
    "\n",
    "\n",
    "It can be seen as a measure of the importance of each factor to the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (net, feats) in enumerate(factors_model.items()):\n",
    "  coef = opt.best_estimator_['clf'].coef_[0][i]\n",
    "  print(f'{net}:\\n'\n",
    "        f'\\tSVM coef: {coef:.2f}\\n'\n",
    "        f'\\tfeatures: {\", \".join(feats)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP\n",
    "\n",
    "We can explain the contribution of each factor to the classification score by plotting their SHAP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "cv = model_selection.RepeatedStratifiedKFold(n_splits=5, n_repeats=100)\n",
    "n_splits = cv.get_n_splits(X, y)\n",
    "\n",
    "shap_values_cv = []\n",
    "expected_value_cv = []\n",
    "X_test_indices_cv = []\n",
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "model = opt.best_estimator_\n",
    "\n",
    "for train, test in tqdm(cv.split(X, y), total=n_splits):\n",
    "\n",
    "  model.fit(X_cfa[train], y[train])\n",
    "  y_pred = model.predict(X_cfa[test])\n",
    "  explainer = shap.Explainer(model.predict_proba,\n",
    "                            X_cfa[train],\n",
    "                            feature_names=list(factors_model.keys()))\n",
    "\n",
    "  shap_values = explainer(X_cfa[test])\n",
    "\n",
    "  shap_values_cv.append(shap_values)\n",
    "  # expected_value_cv.append(explainer.expected_value)\n",
    "  X_test_indices_cv.append(test)\n",
    "  y_test_cv.append(y[test])\n",
    "  y_pred_cv.append(y_pred)\n",
    "\n",
    "# merge CV data\n",
    "y_test = np.hstack(y_test_cv)\n",
    "y_pred = np.hstack(y_pred_cv)\n",
    "\n",
    "# merge CV SHAPs\n",
    "shap_values = shap.Explanation(\n",
    "  values = np.vstack([sh.values[...,1] for sh in shap_values_cv]),\n",
    "  base_values = np.hstack([sh.base_values[...,1] for sh in shap_values_cv]),\n",
    "  data = np.vstack([sh.data for sh in shap_values_cv]),\n",
    "  feature_names=shap_values_cv[0].feature_names,\n",
    "  compute_time=np.sum([sh.compute_time for sh in shap_values_cv]),\n",
    "  output_names=y_encoder.classes_,\n",
    "  output_indexes=y_pred,\n",
    ")\n",
    "\n",
    "\n",
    "shap.plots.beeswarm(shap_values, show=False)\n",
    "plt.suptitle('CV-SHAP values of the latent factors in {} {} dataset'.format(ATLAS, CONNECTIVITY_MEASURE))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(deepcopy(shap_values), plot_type='bar', show=False)\n",
    "\n",
    "plt.suptitle('CV-SHAP values of the latent factors in {} {} dataset'.format(ATLAS, CONNECTIVITY_MEASURE))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision plots\n",
    "\n",
    "n_samples = 100\n",
    "select_mask = np.where(y_pred == y_test)[0]     # correctly classified\n",
    "# select_mask = np.where(y_pred != y_test)[0]   # misclassified\n",
    "# select_mask = np.where(y_pred)[0]             # predicted class\n",
    "# select_mask = np.where(y_test)[0]             # true class\n",
    "\n",
    "select_mask = shap.utils.sample(select_mask, n_samples, random_state=1)\n",
    "\n",
    "highlight_mask = (y_test[select_mask] == 1)\n",
    "\n",
    "plt.figure(figsize=(5,6))\n",
    "\n",
    "shap.plots.decision(.5,\n",
    "                    shap_values.values[select_mask],\n",
    "                    # link='logit',\n",
    "                    # feature_order='hclust',\n",
    "                    # highlight=misclassified,\n",
    "                    # ignore_warnings=True,\n",
    "                    # legend_labels=legend_labels(highlight_mask),\n",
    "                    highlight=highlight_mask,\n",
    "                    xlim=(0,1),\n",
    "                    auto_size_plot=False,\n",
    "                    show=False,\n",
    "                    title='100 misclassified subjects',\n",
    "                    feature_names = list(factors_model.keys()))\n",
    "\n",
    "plt.gca().text(-.15,6.01, 'AVGP', clip_box=True, fontdict=dict(fontsize=14, weight='bold'))\n",
    "plt.gca().text(1.02,6.01, 'NVGP', clip_box=True, fontdict=dict(fontsize=14, weight='bold'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation Importance\n",
    "\n",
    "Another feature importance method is the permutation analysis, where we permute the feature values and compute the classification score. The effect of a feature on the classification is then plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "opt.best_estimator_.fit(X_cfa, y)\n",
    "perm_imp_result = permutation_importance(opt.best_estimator_, X_cfa, y, \n",
    "                                         n_repeats=100,\n",
    "                                         scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "perm_sorted_idx = perm_imp_result.importances_mean.argsort()\n",
    "\n",
    "perm_df = pd.DataFrame(perm_imp_result.importances[perm_sorted_idx].T,\n",
    "             columns=factors_model.keys())\n",
    "sns.boxplot(\n",
    "    data=perm_df,\n",
    "    orient='horizontal',\n",
    "#     labels=feature_names[perm_sorted_idx],\n",
    ")\n",
    "\n",
    "plt.suptitle('Permutation importance of the latent factors in {} {} dataset'.format(ATLAS, CONNECTIVITY_MEASURE))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2 = pd.DataFrame(X_cfa.values, columns=X_cfa.columns)\n",
    "X_debug = pd.DataFrame(X_cfa, columns=(factors_model.keys()))\n",
    "y_debug = y_encoder.inverse_transform(y)\n",
    "X_debug.loc[:,'y'] = y_debug\n",
    "plotting_data = X_debug.melt(id_vars=['y']).rename(columns={'variable':'factor', 'value':'coef', 'y': 'group'})\n",
    "\n",
    "g = sns.lineplot(x='factor', y='coef', hue='group', data=plotting_data)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=14)\n",
    "plt.ylabel('tangent coefficient', fontsize=14)\n",
    "plt.xlabel('network', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cfa_corr = pd.DataFrame(X_cfa).corr()\n",
    "X_cfa_corr.columns = factors_model.keys()\n",
    "X_cfa_corr.index = factors_model.keys()\n",
    "\n",
    "g = sns.clustermap(X_cfa_corr, figsize=(6,6), annot=True, robust=True)\n",
    "\n",
    "g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right', fontsize=14)\n",
    "g.ax_heatmap.set_yticklabels(g.ax_heatmap.get_yticklabels(), fontsize=14)\n",
    "\n",
    "\n",
    "plt.suptitle('Pearson correlation of the latent factors in {} {} dataset'.format(ATLAS, CONNECTIVITY_MEASURE), y=0, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = np.zeros((6,6))\n",
    "n = 6\n",
    "\n",
    "for i, source in enumerate(X_cfa.T):\n",
    "  for j, target in enumerate(X_cfa.T):\n",
    "    target = target[np.argsort(source, kind='quicksort')]\n",
    "    _, inverse, counts = np.unique(target, return_inverse=True, return_counts=True)\n",
    "    right = np.cumsum(counts)[inverse]\n",
    "    left = np.cumsum(np.flip(counts))[(counts.size - 1) - inverse]\n",
    "    coef = 1. - 0.5 * np.abs(np.diff(right)).sum() / np.mean(left * (n - left))\n",
    "    xi[i, j] = coef\n",
    "\n",
    "xi[np.diag_indices(6)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.acnets.connectome._chatterjee import chatterjee_xicoef\n",
    "\n",
    "X_cfa_corr = pd.DataFrame(xi)\n",
    "X_cfa_corr.columns = factors_model.keys()\n",
    "X_cfa_corr.index = factors_model.keys()\n",
    "\n",
    "g = sns.clustermap(X_cfa_corr, figsize=(6,6), annot=True, robust=True)\n",
    "\n",
    "g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right', fontsize=14)\n",
    "g.ax_heatmap.set_yticklabels(g.ax_heatmap.get_yticklabels(), fontsize=14)\n",
    "\n",
    "\n",
    "plt.suptitle('Chatterjee Xi of the latent factors in {} {} connectivities'.format(ATLAS, CONNECTIVITY_MEASURE), y=0, fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34f04479ffaeb5c00adb9e28a92647dce776275bf5ee61de72266754f4451f1a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
