{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity Classifier\n",
    "\n",
    "Steps:\n",
    "- Perform parcellation and extract time series\n",
    "- Aggregate region-level time series into network-level time series (optional)\n",
    "- Measure connectivity matrix and vectorize it\n",
    "- Grid search for optimal parcellation\n",
    "- Calculate cross-validated scores\n",
    "- Permutation testing\n",
    "- Learning curve analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygal as pg\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from python.acnets.pipeline import (ConnectivityExtractor,\n",
    "                                    ConnectivityVectorizer, NetworkAggregator,\n",
    "                                    Parcellation)\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold\n",
    "from sklearn.model_selection import (GridSearchCV, StratifiedShuffleSplit,\n",
    "                                     permutation_test_score)\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_connectivity(subjects=None,\n",
    "          atlas='gordon2014_2mm',\n",
    "          connectivity='correlation',\n",
    "          aggregate_networks=True):\n",
    "    \"\"\"Parcellate regions, aggregate networks, and extract connectivity.\"\"\"\n",
    "\n",
    "    p = Parcellation(atlas)\n",
    "    n = NetworkAggregator(p.labels_)\n",
    "    c = ConnectivityExtractor(connectivity)\n",
    "\n",
    "    if aggregate_networks:\n",
    "        conn = make_pipeline(p, n, c).fit_transform(X)\n",
    "        nodes = n.networks_.to_list()\n",
    "    else:\n",
    "        conn = make_pipeline(p, c).fit_transform(X)\n",
    "        nodes = p.labels_.index.to_list()\n",
    "\n",
    "    conn = xr.DataArray(\n",
    "        conn,\n",
    "        coords={'subject': p.dataset_['subject'],\n",
    "                'node': nodes},\n",
    "        dims=['subject', 'node', 'node'],\n",
    "        name='connectivity')\n",
    "\n",
    "    # select only queried subjects\n",
    "    if subjects is not None:\n",
    "        subjects_1d = subjects.reshape(-1).tolist()\n",
    "        conn = conn.sel(dict(subject=subjects_1d))\n",
    "\n",
    "    return conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_atlas = 'dosenbach2010'\n",
    "_connectivity = 'tangent'\n",
    "conn = extract_connectivity(atlas=_atlas, connectivity=_connectivity)\n",
    "subjects = conn.coords['subject'].values\n",
    "subject_groups = np.array([s[:4] for s in subjects])\n",
    "conn_vec = ConnectivityVectorizer(only_diagonal=True).fit_transform(conn)\n",
    "\n",
    "df = pd.DataFrame(conn_vec, columns=conn.coords['node'].values)\n",
    "df['group'] = subject_groups\n",
    "\n",
    "df = df.melt(id_vars=['group'], var_name='network', value_name='connectivity')\n",
    "\n",
    "# df['group_mean'] = df.groupby(['network'])['connectivity'].transform('mean')\n",
    "# df.sort_values(by='group_mean', ascending=False, inplace=True)\n",
    "\n",
    "n_networks = df['network'].nunique()\n",
    "\n",
    "_, ax = plt.subplots(figsize=(n_networks * .8, 5))\n",
    "sns.lineplot(data=df, x='network', y='connectivity', hue='group', sort=False)\n",
    "plt.xticks(rotation=45, rotation_mode='anchor', ha='right')\n",
    "\n",
    "_atlas = _atlas.replace('_','\\_')\n",
    "plt.suptitle(f'$\\\\bf{{{_atlas}}}$ connectivity ({_connectivity})', y=.93)\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_grid_search_results(grid, score_name='accuracy'):\n",
    "    sns.set_style('ticks')\n",
    "    sns.despine()\n",
    "\n",
    "    results = grid.cv_results_\n",
    "    n_splits = grid.cv.get_n_splits()\n",
    "\n",
    "    param_names = []\n",
    "    for param in results['param_connectivity__kw_args']:\n",
    "        atlas = param['atlas'].replace('_','\\_')\n",
    "        connectivity = param['connectivity']\n",
    "        feature = 'network' if param['aggregate_networks'] else 'region' \n",
    "        param_names.append(f'$\\\\bf{{{atlas}}}$\\n{connectivity} ({feature})')\n",
    "\n",
    "    cv_scores = []\n",
    "    for i in range(n_splits):\n",
    "        scores = results[f'split{i}_test_score']\n",
    "        cv_scores.extend(list(zip(param_names, scores)))\n",
    "\n",
    "    test_results  = pd.DataFrame(cv_scores, columns=['parcellation', score_name])\n",
    "    test_results['mean_score'] = test_results.groupby('parcellation').transform(np.mean)\n",
    "    test_results.sort_values('mean_score', ascending=False, inplace=True)\n",
    "    # DEBUG print(test_results.groupby('parcellation').min())\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(len(param_names) * 1.1, 5))\n",
    "    sns.lineplot(data=test_results.iloc[::-1], x='parcellation', y=score_name, lw=3, sort=False, ax=ax)\n",
    "    sns.scatterplot(data=test_results.iloc[::-1], x='parcellation', y='mean_score', marker='o', s=100,ax=ax)\n",
    "    ax.axhline(.5, linestyle='--', color='red')\n",
    "    lgd = ax.legend(['average', '95% CI', '_average', 'chance'],\n",
    "                    title_fontproperties={'weight':'bold', 'size':'x-large'},\n",
    "                    prop={'size':'xx-large'},\n",
    "                    title=f'{n_splits} $\\\\times$ 5-fold CV')\n",
    "    ax.get_legend()._legend_box.align = 'left'\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('accuracy', fontsize='xx-large')\n",
    "    plt.xticks(rotation=45, ha='right', fontsize='x-large', rotation_mode='anchor')\n",
    "    plt.suptitle('$\\\\bf{SVM}$ classification accuracy (validation set)', fontsize='xx-large', y=.95)\n",
    "    plt.grid(axis='y')\n",
    "\n",
    "    # table = plt.table(cellText=[['s','s2','s3','s4','s5'],['s','s2','s','s','s']],\n",
    "    #                   rowLabels=['atlas','connectivity'],\n",
    "    #                   rowColours=['lightgreen','gray'],\n",
    "    #                 #   colLabels=['1','2'],\n",
    "    #                 colLoc=['center','center'],\n",
    "    #                   loc='bottom')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# plot_grid_search_results(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe  = Pipeline([\n",
    "    ('connectivity', FunctionTransformer(extract_network_connectivity)),\n",
    "    ('vectorize', ConnectivityVectorizer()),\n",
    "    # ('select', SelectFromModel(SVC(kernel='linear'))),\n",
    "    ('select', SelectFromModel(LinearSVC(C=5, max_iter=100000))),\n",
    "    ('zv', VarianceThreshold(threshold=0)),\n",
    "    # ('svm', SVC(kernel='linear', probability=True))\n",
    "    ('svm', LinearSVC(C=.1, max_iter=100000))\n",
    "    # ('rfc', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "params = {\n",
    "    'connectivity__kw_args': [\n",
    "        \n",
    "        dict(atlas='gordon2014_2mm', connectivity='correlation', aggregate_networks=False),\n",
    "        # dict(atlas='gordon2014_2mm', connectivity='tangent', aggregate_networks=False),\n",
    "        # dict(atlas='gordon2014_2mm', connectivity='partial correlation', aggregate_networks=False),\n",
    "\n",
    "        dict(atlas='gordon2014_2mm', connectivity='correlation', aggregate_networks=True),\n",
    "        dict(atlas='gordon2014_2mm', connectivity='tangent', aggregate_networks=True),\n",
    "        dict(atlas='gordon2014_2mm', connectivity='precision', aggregate_networks=True),\n",
    "        dict(atlas='gordon2014_2mm', connectivity='partial correlation', aggregate_networks=True),\n",
    "        dict(atlas='gordon2014_2mm', connectivity='chatterjee', aggregate_networks=True),\n",
    "\n",
    "        dict(atlas='dosenbach2010', connectivity='correlation', aggregate_networks=False),\n",
    "        dict(atlas='dosenbach2010', connectivity='tangent', aggregate_networks=False),\n",
    "        dict(atlas='dosenbach2010', connectivity='partial correlation', aggregate_networks=False),\n",
    "\n",
    "        dict(atlas='dosenbach2010', connectivity='correlation', aggregate_networks=True),\n",
    "        dict(atlas='dosenbach2010', connectivity='tangent', aggregate_networks=True),\n",
    "        dict(atlas='dosenbach2010', connectivity='precision', aggregate_networks=True),\n",
    "        dict(atlas='dosenbach2010', connectivity='partial correlation', aggregate_networks=True),\n",
    "        dict(atlas='dosenbach2010', connectivity='chatterjee', aggregate_networks=True),\n",
    "\n",
    "        dict(atlas='difumo_64_2mm', connectivity='correlation', aggregate_networks=True),\n",
    "        dict(atlas='difumo_64_2mm', connectivity='tangent', aggregate_networks=True),\n",
    "        dict(atlas='difumo_64_2mm', connectivity='precision', aggregate_networks=True),\n",
    "        dict(atlas='difumo_64_2mm', connectivity='partial correlation', aggregate_networks=True),\n",
    "        dict(atlas='difumo_64_2mm', connectivity='chatterjee', aggregate_networks=True)\n",
    "\n",
    "    ],\n",
    "    # 'select__estimator__C': [0.1, .3, .5, 1, 3, 5],\n",
    "    # 'svm__C': [0.1, .3, .5, 1, 3, 5],\n",
    "    # 'svm__kernel': ['linear', 'rbf'],\n",
    "}\n",
    "\n",
    "subjects = extract_network_connectivity().coords['subject'].values\n",
    "y = np.array([s[:4] for s in subjects])\n",
    "X = subjects.reshape(-1, 1)\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25)\n",
    "\n",
    "grid = GridSearchCV(pipe, params, verbose=3, cv=cv, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_estimator_)\n",
    "plot_grid_search_results(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-correlation (DEBUG)\n",
    "\n",
    "import sklearn\n",
    "sklearn.set_config(display='diagram')\n",
    "pipe\n",
    "\n",
    "import statsmodels.api as sm\n",
    "sm.tsa.stattools.ccf([1,2,3,4,5,6,7,8,0], [0,0,1,2,3,4,5,6,7], adjusted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# grid.best_estimator_.named_steps['select'].estimator_.coef_\n",
    "obs_score, perm_scores, pvalue = permutation_test_score(grid.best_estimator_, X, y, scoring='accuracy', n_permutations=5, verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(8,5))\n",
    "g = sns.histplot(perm_scores, kde=True, ax=ax, color='red', lw=0)\n",
    "ax.axvline(obs_score, ls='--', color='blue', lw=3)\n",
    "plt.xlabel('accuracy', fontsize='xx-large')\n",
    "plt.xticks(fontsize='x-large')\n",
    "ax.text(x=obs_score - .01,\n",
    "        y=ax.get_ylim()[1] * .85,\n",
    "        ha='right',\n",
    "        color='blue',\n",
    "        s=f'Accuracy = {obs_score:.2f}\\n(p = {pvalue:.3f})', fontsize='xx-large')\n",
    "\n",
    "plt.suptitle('$\\\\bf{SVM}$ permutation testing\\n$\\\\bf{Connectivity}$: dosenbach2010 network correlation',\n",
    "             ha='left',\n",
    "             x = 0.12,\n",
    "             y=1.01, fontsize='xx-large')\n",
    "plt.legend(['permutation scores', 'observed score'], loc='upper left', fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP\n",
    "import shap\n",
    "\n",
    "shap_values_cv = []\n",
    "X_test_indices_cv = []\n",
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "expected_value_cv = []\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=20)\n",
    "\n",
    "n_splits = cv.get_n_splits(X, y)\n",
    "\n",
    "for train, test in tqdm(cv.split(X, y), total=n_splits):\n",
    "\n",
    "    # train the model\n",
    "    grid.best_estimator_.fit(X[train], y[train])\n",
    "    y_pred = grid.best_estimator_.predict(X[test])\n",
    "\n",
    "    explainer = shap.KernelExplainer(\n",
    "        grid.best_estimator_.named_steps['svm'].predict, data=X[train],\n",
    "        # feature_names=feature_names,\n",
    "        # algorithm='tree',\n",
    "        # approximate=True,\n",
    "        # model_output='raw',\n",
    "        # feature_perturbation='tree_path_dependent',\n",
    "        # feature_perturbation='interventional',\n",
    "    )\n",
    "\n",
    "    shap_values = explainer.shap_values(X[test])#, check_additivity=True)\n",
    "\n",
    "    shap_values_cv.append(shap_values)\n",
    "    expected_value_cv.append(explainer.expected_value)\n",
    "    X_test_indices_cv.append(test)\n",
    "    y_test_cv.append(y[test])\n",
    "    y_pred_cv.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_connectivity_heatmap(all_conns, title, plot_diff, ax):\n",
    "\n",
    "    if plot_diff:\n",
    "        avgp = conn.subject.str.contains(\"AVGP\").values\n",
    "        data = conn[avgp].mean(dim='subject').values - conn[~avgp].mean(dim='subject').values\n",
    "    else:\n",
    "        data = all_conns.mean(dim='subject')\n",
    "\n",
    "    sns.heatmap(\n",
    "        data,\n",
    "        yticklabels=conn.coords['node'].values,\n",
    "        xticklabels=conn.coords['node'].values,\n",
    "        annot=True, fmt='.2f',\n",
    "        ax=ax,\n",
    "        square=True,\n",
    "        # figsize=(7, 7),\n",
    "        # dendrogram_ratio=0.001,\n",
    "        # cbar_pos=(1., 0.3, 0.03, 0.6)\n",
    "        # cmap='rainbow',\n",
    "        # cbar=False,\n",
    "    )\n",
    "    ax.set_title(f'$\\\\bf{{{title}}}$', fontsize='xx-large')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor', fontsize='x-large')\n",
    "    ax.set_yticklabels(ax.get_xticklabels(), rotation=0, ha='right', rotation_mode='anchor', fontsize='x-large')\n",
    "\n",
    "\n",
    "conn = extract_network_connectivity(atlas='dosenbach2010', connectivity='correlation')\n",
    "avgp = conn.subject.str.contains(\"AVGP\").values\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(17, 7))\n",
    "# plot_connectivity_heatmap(conn[avgp], title='AVGP', plot_diff=False, ax=axes[0])\n",
    "# plot_connectivity_heatmap(conn[~avgp], title='NVGP', plot_diff=False, ax=axes[1])\n",
    "plot_connectivity_heatmap(conn[~avgp], title='AVGP - NVGP', plot_diff=True, ax=axes)\n",
    "\n",
    "plt.suptitle('dosenbach2010 correlation connectivity (network)', fontsize='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = pg.Line(_self_close=False, _max=10)\n",
    "\n",
    "for (network,subject),data  in network_timeseries['timeseries_mean'].iteritems():\n",
    "  if network in ['Visual','FrontoParietal']:\n",
    "    chart.add(network, data)\n",
    "\n",
    "from IPython.display import SVG\n",
    "SVG(chart.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Again, a very dirty but quick EPI signal level in Cerebellum\n",
    "\n",
    "Is it clear that there is an appreciable reduction of tSNR in the brainstem and cerebellum compared to the cerebrum, caused by lower mean signal and/or increased signal variance in the those regions (as measured by tSNR)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting, maskers\n",
    "from tqdm  import tqdm\n",
    "import nibabel as nib \n",
    "from pathlib import Path\n",
    "import datalad.api as dlapi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tsnr_images = []\n",
    "\n",
    "# fmriprep\n",
    "dataset = dlapi.Dataset('data/julia2018/derivatives/fmriprep_2020')\n",
    "scan_imgs = Path(dataset.path).glob('sub-*/ses-rest/func/*_bold.nii.gz')\n",
    "mask_imgs = Path(dataset.path).glob('sub-*/ses-rest/func/*-brain_mask.nii.gz')\n",
    "# raw\n",
    "# dataset = dlapi.Dataset('data/julia2018')\n",
    "# scan_imgs  = Path(dataset.path).glob('sub-*/ses-rest/func/*_bold.nii.gz')\n",
    "\n",
    "\n",
    "for img, mask_img in tqdm(zip(scan_imgs,  mask_imgs)):\n",
    "  dlapi.get(img)\n",
    "  dlapi.get(mask_img)\n",
    "\n",
    "  img = nib.load(img)\n",
    "  mask_img = nib.load(mask_img)\n",
    "\n",
    "  masker = maskers.NiftiMasker(mask_img)\n",
    "  masked_img = masker.fit_transform(img)\n",
    "  masked_img = masker.inverse_transform(masked_img)\n",
    "\n",
    "  data_avg = np.mean(masked_img.get_fdata(), axis=-1)\n",
    "  data_std = np.std(masked_img.get_fdata(), axis=-1)\n",
    "  tsnr = data_avg / data_std\n",
    "  tsnr = np.where(data_std > 0.0, tsnr, 0.0)\n",
    "  tsnr_img = nib.nifti1.Nifti1Image(tsnr, masked_img.affine)\n",
    "\n",
    "  tsnr_images.append(tsnr_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only works on fmriprep \n",
    "\n",
    "from nilearn import image\n",
    "import nibabel as nib\n",
    "\n",
    "mean_tsnr_img = image.mean_img(tsnr_images)\n",
    "\n",
    "\n",
    "plotting.plot_epi(mean_tsnr_img, cut_coords=(-21,-79,-33),\n",
    "                    black_bg=False,\n",
    "                    colorbar=True,\n",
    "                    title=f'Mean tSNR across all subjects (dosenbach2010 inf cerebellum 150)',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_coords_dosenbach_2010\n",
    "\n",
    "atlas = fetch_coords_dosenbach_2010(legacy_format=False)\n",
    "\n",
    "labels = pd.DataFrame(atlas.labels)\n",
    "labels['network'] = atlas.networks.reset_index(drop=True)\n",
    "# atlas.networks\n",
    "# atlas.rois\n",
    "labels[['x','y','z']] =  atlas.rois.reset_index(drop=True)\n",
    "cerebellum_rois = labels.query('network == \"cerebellum\"')\n",
    "cerebellum_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for _,roi,network,x,y,z  in cerebellum_rois.itertuples():\n",
    "    plotting.plot_epi(mean_tsnr_img, colorbar=True,\n",
    "                    # cut_coords=(18,-81,-32),\n",
    "                    cut_coords=(x,y,z),\n",
    "                    # cmap='cold_hot',\n",
    "                    black_bg=False,\n",
    "                    title=f'Mean tSNR across all subjects (dosenbach2010 {roi})',\n",
    "                    cbar_tick_format='%.2f')\n",
    "    plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tsnr_img in tsnr_images:\n",
    "    plotting.plot_epi(tsnr_img, colorbar=True,\n",
    "                    # cut_coords=(0,-60,-25),\n",
    "                    # cmap='cold_hot',\n",
    "                    cbar_tick_format='%.2f')\n",
    "    plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirty Network masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import maskers, datasets, plotting, image, surface\n",
    "import numpy as np\n",
    "from python.acnets.parcellations import gordon\n",
    "\n",
    "atlas = gordon.fetch_atlas()\n",
    "\n",
    "maps_data = image.get_data(atlas['maps'])\n",
    "atlas.labels['network'] = atlas.labels['network'].astype('category')\n",
    "region2network_mapping = atlas.labels['network'].cat.codes + 1\n",
    "region2network_mapping = region2network_mapping.to_dict()\n",
    "# atlas.labels['network'].cat.categories\n",
    "none_regions = atlas.labels.query('network == \"None\"').index\n",
    "none_idx = atlas.labels['network'].cat.categories.to_list().index('None') + 1\n",
    "map_r2n = lambda x: region2network_mapping[int(x)] if x not in [0,none_idx] else 0\n",
    "maps_data = np.vectorize(map_r2n)(maps_data)\n",
    "\n",
    "new_maps = image.new_img_like(atlas['maps'], maps_data)\n",
    "new_maps.to_filename('a.nii.gz')\n",
    "\n",
    "fsaverage = datasets.fetch_surf_fsaverage()\n",
    "\n",
    "# plotting.plot_epi(new_maps, colorbar=True)\n",
    "# plotting.plot_img(new_maps, colorbar=True)\n",
    "# plotting.plot_roi(new_maps, title='Gordon Atlas', colorbar=True)\n",
    "\n",
    "# aa = surface.vol_to_surf(new_maps, fsaverage.pial_left)\n",
    "\n",
    "# plotting.view(fsaverage['pial_left'], roi_map=aa,\n",
    "#                        hemi='left', view='lateral',\n",
    "#                        bg_map=fsaverage['sulc_left'], bg_on_data=True,\n",
    "#                        darkness=.5)\n",
    "\n",
    "plotting.view_img(new_maps, symmetric_cmap=False, black_bg=False).open_in_browser()\n",
    "\n",
    "# plotting.view_surf(fsaverage.white_right, aa).open_in_browser()\n",
    "# plotting.plot_glass_brain(new_maps, colorbar=True, annotate=True)\n",
    "# plotting.plot_epi(net_maps,cut_coords=(0,-10,-55), colorbar=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34f04479ffaeb5c00adb9e28a92647dce776275bf5ee61de72266754f4451f1a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
