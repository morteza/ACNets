{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACNets: Connectivity Classifier\n",
    "\n",
    "This notebook fits a binary classifier to predict participant's group, AVGP or NVGP, using functional connectivity matrices. As input, it takes upper-triangular connectivity matrices for each participant.\n",
    "\n",
    "To address the concerns about small sample size and test/train splits, results are evaluated using 5-fold cross-validated permutation testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2022-02-19T10:17:53.129834+01:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.10\n",
      "IPython version      : 8.0.1\n",
      "\n",
      "conda environment: acnets\n",
      "\n",
      "Compiler    : Clang 11.1.0 \n",
      "OS          : Darwin\n",
      "Release     : 21.3.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: MP0159\n",
      "\n",
      "pandas    : 1.4.0\n",
      "matplotlib: 3.5.1\n",
      "sklearn   : 1.0.2\n",
      "xgboost   : 1.5.1\n",
      "re        : 2.2.1\n",
      "numpy     : 1.21.5\n",
      "xarray    : 0.21.1\n",
      "seaborn   : 0.11.2\n",
      "sys       : 3.9.10 | packaged by conda-forge | (main, Feb  1 2022, 21:28:27) \n",
      "[Clang 11.1.0 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set('notebook')\n",
    "\n",
    "from sklearn import preprocessing, model_selection, metrics, ensemble, multioutput\n",
    "from sklearn import decomposition, cross_decomposition, feature_selection, dummy, svm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import xgboost\n",
    "\n",
    "# Technical reproducibility\n",
    "%reload_ext watermark\n",
    "%watermark -iv -co -ituhmv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlases = ['dosenbach2007', 'dosenbach2010', 'difumo_64_2',]# 'difumo_128_2',]# 'difumo_1024_2']\n",
    "\n",
    "connectivity_measures = ['tangent', 'precision', 'correlation',\n",
    "                         'covariance', 'partial_correlation']\n",
    "\n",
    "DATASETS = dict()\n",
    "\n",
    "for atlas in atlases:\n",
    "  for connectivity in connectivity_measures:\n",
    "    _conn_key = f'{connectivity}_connectivity'\n",
    "    ds = xr.open_dataset(f'data/julia2018_resting/connectivity_{atlas}.nc')\n",
    "    _conn = ds[_conn_key]\n",
    "    _conn.coords['group'] = ds.group\n",
    "    _conn['inverse_efficiency_score_ms'] = ds['inverse_efficiency_score_ms']\n",
    "    DATASETS[f'{atlas}_{connectivity}'] = _conn\n",
    "    \n",
    "    if 'difumo_names' in ds.coords:\n",
    "      _conn.coords['region'] = ds.coords['difumo_names'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification Model\n",
    "\n",
    "-[ ] TODO: replicate https://www.frontiersin.org/articles/10.3389/fnhum.2014.00425/full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALT1: single-output classifiers, e.g., SVM, boosting\n",
    "# model = svm.SVC(kernel='linear', C=1, probability=True)\n",
    "# model =ensemble.AdaBoostClassifier(model, n_estimators=100, algorithm='SAMME.R')\n",
    "# model =ensemble.GradientBoostingClassifier(n_estimators=100)\n",
    "\n",
    "# ALT2: chance level\n",
    "# model = dummy.DummyClassifier(strategy='uniform')\n",
    "\n",
    "# ALT3: multi-output (classification + behavioral regression)\n",
    "# model = multioutput.MultiOutputClassifier(ensemble.GradientBoostingClassifier())\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('zerovar', feature_selection.VarianceThreshold()),\n",
    "    # ('select', feature_selection.SelectKBest()),\n",
    "    # ('rfe', feature_selection.RFE(svc)),\n",
    "    # ('standard_scaler', preprocessing.StandardScaler()), \n",
    "    # ('reducer', UMAP(n_components=3)), \n",
    "    # ('reducer', decomposition.PCA()),\n",
    "    # ('reducer', cross_decomposition.PLSCanonical()),    \n",
    "    ('model', svm.SVC(kernel='rbf', C=1, probability=True)),\n",
    "    # ('model', xgboost.XGBClassifier(n_jobs=-1, use_label_encoder=False, eval_metric='logloss')),\n",
    "], verbose=False)\n",
    "\n",
    "param_grid = {\n",
    "    # 'zerovar__threshold': [0],\n",
    "    # 'select__k': np.linspace(1, X.shape[1], num=100, endpoint=True, dtype='int'),\n",
    "    # 'rfe__n_features_to_select': [.1, .2, .5, 1.],\n",
    "    # 'reducer__n_neighbors': [1, 2, 3, 4, 5, 10],  # UMAP\n",
    "    # 'reducer__n_components': [2,3,5],  # UMAP\n",
    "    # 'reducer__n_components': range(1, 10),  # PCA\n",
    "    # 'model__n_estimators': [10, 100, 1000],  # XGBClassifier, GradientBoostingClassifier\n",
    "    # 'model__estimator__n_estimators': [10, 100],  # MultiOutputClassifier\n",
    "}\n",
    "\n",
    "grid = model_selection.GridSearchCV(\n",
    "    pipe, param_grid,\n",
    "    # cv=model_selection.LeaveOneOut(), scoring='accuracy',\n",
    "    cv=5, scoring='roc_auc',\n",
    "    # scoring=['accuracy', 'roc_auc', 'f1', 'precision', 'recall'], refit='accuracy',\n",
    "    n_jobs=-1, verbose=1,\n",
    ")\n",
    "\n",
    "# rfe_model = feature_selection.RFECV(grid)\n",
    "# rfe_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tune the hyper-parameters and train the model. We then evaluate the fitted model on the held-out test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "_tmp_results = []  # will be converted to DataFrame and deleted later\n",
    "\n",
    "for ds_name, ds in DATASETS.items():\n",
    "  \n",
    "  atlas_name = re.findall(r'^(dosenbach20\\d\\d|difumo_\\d\\d_\\d).*$',ds_name)[0]\n",
    "  \n",
    "  connectivity_measure_name = ds_name.replace(atlas_name + '_', '')\n",
    "\n",
    "  # 1. input (vectorized connectivity matrix)\n",
    "  X = np.array([subj_conn[np.triu_indices_from(subj_conn)] for subj_conn in ds.values])\n",
    "\n",
    "  # 1.1. threshold X\n",
    "  X_threshold = np.median(X, axis=1) + np.std(X, axis=1)\n",
    "  X = np.where(np.abs(X) >= X_threshold.reshape(-1,1), X, 0)\n",
    "\n",
    "  # 2. output (AVGP vs NVGP encoded as integers)\n",
    "  y_encoder = preprocessing.LabelEncoder()\n",
    "  y = y_encoder.fit_transform(ds['group'])\n",
    "\n",
    "  # 2.1. behavioral outputs (inverse efficiency scores in millis)\n",
    "  y_beh = ds['inverse_efficiency_score_ms'].values\n",
    "\n",
    "  # 3. remove subjects with missing behavioral data and duplicate scans\n",
    "  # FIXME: this is a hack, make sure NEW subjects are different from OLD ones\n",
    "  # subject_labels = xr.concat([ds['subject'], ds['subject'] + 'NEW'], dim='subject')\n",
    "  # invalid_subjects = subject_labels.to_series().duplicated(keep='first')[32:]\n",
    "  # invalid_subjects = invalid_subjects | np.isnan(y_beh)\n",
    "  invalid_subjects = np.isnan(y_beh)\n",
    "  \n",
    "  X = X[~invalid_subjects]\n",
    "  y = y[~invalid_subjects]\n",
    "  y_beh = y_beh[~invalid_subjects]\n",
    "\n",
    "  # DEBUG\n",
    "  print(f'[{ds_name}]\\n'\n",
    "        f'{X.shape[1]} features, {X.shape[0]} subjects, '\n",
    "        f'{np.unique(y).shape[0]} classes.')\n",
    "  \n",
    "  train, test = model_selection.train_test_split(\n",
    "    range(len(X)),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    stratify=y)\n",
    "\n",
    "  # fit\n",
    "  grid.fit(X[train], y[train])\n",
    "\n",
    "  # evaluate\n",
    "  score_train = grid.score(X[train], y[train])\n",
    "  score_test = grid.score(X[test], y[test])\n",
    "\n",
    "  # clear_output()\n",
    "\n",
    "  # report scores and hyperparameters\n",
    "  print(f'train set score (roc_auc): {score_train:.2f}')\n",
    "  print(f'test set score (roc_auc): {score_test:.2f}')\n",
    "  \n",
    "  print('Permutation testing...', end=' ')\n",
    "  \n",
    "  \n",
    "  cv = model_selection.StratifiedKFold(5)\n",
    "  #cv=model_selection.LeaveOneOut()\n",
    "\n",
    "  # we don't have a hyperparameter so we pass 'pipe' instead of 'grid'\n",
    "  obs_score, perm_scores, p_value = model_selection.permutation_test_score(\n",
    "    pipe, X, y,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    #scoring='accuracy',  # LOO cannot handle roc-auc\n",
    "    n_permutations=1000,\n",
    "    n_jobs=-1, verbose=0)\n",
    "\n",
    "  _tmp_results.append({\n",
    "    'atlas': atlas_name,\n",
    "    'randomized': False,\n",
    "    'connectivity_measure': connectivity_measure_name,\n",
    "    'observed_score': obs_score,\n",
    "    'permutation_scores': perm_scores,\n",
    "    'p_value': p_value,\n",
    "  })\n",
    "  \n",
    "  # permute a randomized X to make sure the model does not pick-up subject labels\n",
    "  X_rand = np.random.randn(*X.shape)\n",
    "  rnd_score, rnd_perm_scores, rnd_p_value = model_selection.permutation_test_score(\n",
    "    pipe, X_rand, y,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    #scoring='accuracy',  # LOO cannot handle roc-auc\n",
    "    n_permutations=10,\n",
    "    n_jobs=-1, verbose=0)\n",
    "  \n",
    "  _tmp_results.append({\n",
    "    'atlas': atlas_name,\n",
    "    'randomized': True,\n",
    "    'connectivity_measure': connectivity_measure_name,\n",
    "    'observed_score': rnd_score,\n",
    "    'permutation_scores': rnd_perm_scores,\n",
    "    'p_value': rnd_p_value,\n",
    "  })\n",
    "  \n",
    "  print('done!')\n",
    "  print('--------')\n",
    "\n",
    "print('Finished!')\n",
    "\n",
    "perm_results = pd.DataFrame(_tmp_results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation\n",
    "Below is the confusion matrix of the classifier on the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_datasets = len(perm_results)\n",
    "\n",
    "fig, axes = plt.subplots(math.ceil(n_datasets/3), 3, sharey=True,\n",
    "                         figsize=(15, 5 * math.ceil(n_datasets/3)),\n",
    "                         gridspec_kw=dict(wspace=.3, hspace=.3))\n",
    "\n",
    "for i, atlas_name, is_rnd, conn_measure, obs_score, scores, p_value in perm_results.itertuples():\n",
    "  ax = axes.flatten()[i]\n",
    "  g = sns.histplot(scores, kde=True, ax=ax)\n",
    "  \n",
    "  \n",
    "  ax.axvline(obs_score, ls='--', color='blue')\n",
    "\n",
    "  ax.set(xlabel='ROC AUC')\n",
    "  ax.text(x=obs_score + .02,\n",
    "          y=ax.get_ylim()[1] * .7,\n",
    "          s=f'AUC = {obs_score:.2f}\\n(p-value: {p_value:.3f})')\n",
    "  \n",
    "  ax.set_title(f'{atlas_name} {conn_measure} '\n",
    "               f'({\"random\" if is_rnd else \"original\"})', color='blue')\n",
    "\n",
    "plt.suptitle('5-fold cross-validated permutation testing\\n'\n",
    "             'Red lines are the scores without permutation '\n",
    "             f'and blue curves show $H_0$ ({len(scores)} permuted y labels)',\n",
    "             y=.95, x=.08, ha='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIXME: Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "pipe.fit(X, y)\n",
    "perm_imp_result = permutation_importance(pipe, X, y, \n",
    "                                         n_repeats=100,\n",
    "                                         scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "perm_sorted_idx = perm_imp_result.importances_mean.argsort()\n",
    "\n",
    "# sns.boxplot(\n",
    "#     result.importances[perm_sorted_idx].T,\n",
    "#     vert=False,\n",
    "#     labels=data.feature_names[perm_sorted_idx],\n",
    "# )\n",
    "\n",
    "\n",
    "perm_imp_result.importances[perm_sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "corr = spearmanr(X).correlation\n",
    "\n",
    "# Ensure the correlation matrix is symmetric\n",
    "corr = (corr + corr.T) / 2\n",
    "np.fill_diagonal(corr, 1)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10, 10))\n",
    "\n",
    "# We convert the correlation matrix to a distance matrix before performing\n",
    "# hierarchical clustering using Ward's linkage.\n",
    "distance_matrix = 1 - np.abs(corr)\n",
    "dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "dendro = hierarchy.dendrogram(\n",
    "    dist_linkage, labels=feature_names.tolist(), ax=ax1, leaf_rotation=90\n",
    ")\n",
    "\n",
    "dendro_idx = np.arange(0, len(dendro[\"ivl\"]))\n",
    "\n",
    "\n",
    "\n",
    "ax2.imshow(corr[dendro[\"leaves\"], :][:, dendro[\"leaves\"]])\n",
    "ax2.set_xticks(dendro_idx)\n",
    "ax2.set_yticks(dendro_idx)\n",
    "ax2.set_xticklabels(dendro[\"ivl\"], rotation=\"vertical\")\n",
    "ax2.set_yticklabels(dendro[\"ivl\"])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "cluster_ids = hierarchy.fcluster(dist_linkage, 1, criterion=\"distance\")\n",
    "cluster_id_to_feature_ids = defaultdict(list)\n",
    "for idx, cluster_id in enumerate(cluster_ids):\n",
    "    cluster_id_to_feature_ids[cluster_id].append(idx)\n",
    "selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
    "\n",
    "X_clustered = X[:, selected_features]\n",
    "\n",
    "# Permmutation Importance\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "grid.fit(X_clustered[train], y[train])\n",
    "perm_imp_result = permutation_importance(grid, X_clustered[test], y[test],\n",
    "                                         scoring='roc_auc',\n",
    "                                         n_repeats=100)\n",
    "\n",
    "sorted_idx = perm_imp_result.importances_mean.argsort()[::-1][:10][::-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.boxplot(\n",
    "    perm_imp_result.importances[sorted_idx].T,\n",
    "    labels = feature_names[np.array(selected_features)[sorted_idx]],\n",
    "    vert=False,\n",
    ")\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34f04479ffaeb5c00adb9e28a92647dce776275bf5ee61de72266754f4451f1a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('acnets')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
