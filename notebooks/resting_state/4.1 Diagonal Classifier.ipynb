{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACNets: Diagonal Connectivity Classifier\n",
    "\n",
    "This notebook fits a binary classifier to predict participant's group, AVGP or NVGP, using functional connectivity matrices. As input, it takes upper-triangular connectivity matrices for each participant.\n",
    "\n",
    "To address the concerns about small sample size and test/train splits, results are evaluated using 5-fold cross-validated permutation testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2022-02-23T14:18:03.276085+01:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.10\n",
      "IPython version      : 8.0.1\n",
      "\n",
      "conda environment: acnets\n",
      "\n",
      "Compiler    : Clang 11.1.0 \n",
      "OS          : Darwin\n",
      "Release     : 21.3.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: MP0159\n",
      "\n",
      "sys       : 3.9.10 | packaged by conda-forge | (main, Feb  1 2022, 21:28:27) \n",
      "[Clang 11.1.0 ]\n",
      "numpy     : 1.21.5\n",
      "seaborn   : 0.11.2\n",
      "sklearn   : 1.0.2\n",
      "pandas    : 1.4.0\n",
      "matplotlib: 3.5.1\n",
      "re        : 2.2.1\n",
      "xarray    : 0.21.1\n",
      "skopt     : 0.9.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set('notebook')\n",
    "\n",
    "from sklearn import preprocessing, model_selection, metrics, ensemble, multioutput\n",
    "from sklearn import decomposition, cross_decomposition, feature_selection, dummy, svm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import skopt\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "from python.acnets.datasets import load_connectivity\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Technical reproducibility\n",
    "%reload_ext watermark\n",
    "%watermark -iv -co -ituhmv\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlases = ['dosenbach2010']\n",
    "connectivity_measures = ['tangent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 50/150 [01:21<02:42,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set score (roc_auc): 0.80\n",
      "test set score (roc_auc): 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.861111111111111 [0.36666667 0.37222222 0.57222222 0.40555556 0.50555556 0.44444444\n",
      " 0.76666667 0.51666667 0.41111111 0.63888889 0.42777778 0.72222222\n",
      " 0.35555556 0.46111111 0.88888889 0.37777778 0.52222222 0.87777778\n",
      " 0.58888889 0.48333333 0.66111111 0.61666667 0.53333333 0.38333333\n",
      " 0.50555556 0.40555556 0.56111111 0.56666667 0.71111111 0.37777778\n",
      " 0.63333333 0.29444444 0.59444444 0.41111111 0.62777778 0.80555556\n",
      " 0.40555556 0.48888889 0.32777778 0.54444444 0.3        0.41666667\n",
      " 0.24444444 0.68888889 0.56111111 0.58333333 0.35       0.59444444\n",
      " 0.5        0.50555556 0.46666667 0.49444444 0.63888889 0.49444444\n",
      " 0.3        0.50555556 0.4        0.72777778 0.77777778 0.3\n",
      " 0.45555556 0.46111111 0.52777778 0.42222222 0.51666667 0.50555556\n",
      " 0.74444444 0.47222222 0.6        0.57222222 0.54444444 0.46111111\n",
      " 0.45       0.24444444 0.33888889 0.44444444 0.53333333 0.56666667\n",
      " 0.41111111 0.48333333 0.46666667 0.36111111 0.18888889 0.48888889\n",
      " 0.4        0.48333333 0.56111111 0.50555556 0.65       0.66666667\n",
      " 0.65       0.57222222 0.62777778 0.50555556 0.22222222 0.4\n",
      " 0.38333333 0.58333333 0.48888889 0.38333333 0.43333333 0.65\n",
      " 0.47777778 0.23888889 0.32222222 0.55       0.5        0.37777778\n",
      " 0.67222222 0.48333333 0.62222222 0.63333333 0.3        0.32777778\n",
      " 0.63888889 0.45555556 0.22222222 0.53333333 0.36111111 0.43888889\n",
      " 0.68333333 0.34444444 0.64444444 0.3        0.41666667 0.47222222\n",
      " 0.57222222 0.52222222 0.52777778 0.63888889 0.75555556 0.53888889\n",
      " 0.7        0.77222222 0.27777778 0.53888889 0.18333333 0.68333333\n",
      " 0.51666667 0.58888889 0.43333333 0.6        0.42777778 0.63888889\n",
      " 0.56666667 0.47222222 0.66666667 0.47222222 0.47777778 0.57777778\n",
      " 0.27777778 0.36111111 0.56111111 0.31666667 0.45555556 0.55\n",
      " 0.73888889 0.44444444 0.33333333 0.65555556 0.61666667 0.6\n",
      " 0.45555556 0.47222222 0.2        0.61111111 0.31111111 0.36111111\n",
      " 0.33333333 0.46111111 0.33333333 0.66111111 0.47777778 0.65\n",
      " 0.73888889 0.36666667 0.43333333 0.47222222 0.5        0.43888889\n",
      " 0.61666667 0.36666667 0.36666667 0.47222222 0.63333333 0.50555556\n",
      " 0.33333333 0.30555556 0.45       0.44444444 0.47222222 0.55\n",
      " 0.66111111 0.58333333 0.72777778 0.62222222 0.57777778 0.48888889\n",
      " 0.49444444 0.4        0.40555556 0.51111111 0.38888889 0.82222222\n",
      " 0.50555556 0.65555556 0.43333333 0.54444444 0.53333333 0.60555556\n",
      " 0.70555556 0.7        0.64444444 0.52222222 0.63333333 0.51666667\n",
      " 0.43333333 0.47777778 0.37222222 0.53888889 0.3        0.53888889\n",
      " 0.36111111 0.46666667 0.53333333 0.74444444 0.58888889 0.74444444\n",
      " 0.63333333 0.24444444 0.56666667 0.52777778 0.68888889 0.58888889\n",
      " 0.45       0.48333333 0.45555556 0.52222222 0.53888889 0.53333333\n",
      " 0.35       0.7        0.4        0.44444444 0.37222222 0.56666667\n",
      " 0.36666667 0.44444444 0.48888889 0.61666667 0.55       0.53888889\n",
      " 0.6        0.51111111 0.68888889 0.56666667 0.5        0.31666667\n",
      " 0.36666667 0.53333333 0.51111111 0.48888889 0.50555556 0.50555556\n",
      " 0.4        0.51666667 0.61111111 0.5        0.43333333 0.43888889\n",
      " 0.58888889 0.31666667 0.46111111 0.45       0.57222222 0.54444444\n",
      " 0.33888889 0.3        0.30555556 0.57777778 0.59444444 0.62222222\n",
      " 0.50555556 0.62777778 0.21111111 0.27777778 0.33888889 0.41666667\n",
      " 0.30555556 0.68333333 0.37222222 0.63333333 0.42777778 0.62777778\n",
      " 0.38888889 0.48888889 0.45555556 0.43333333 0.55555556 0.42222222\n",
      " 0.55       0.58333333 0.52222222 0.42222222 0.33888889 0.70555556\n",
      " 0.33888889 0.71666667 0.45       0.59444444 0.6        0.57777778\n",
      " 0.46111111 0.68888889 0.45555556 0.63333333 0.69444444 0.71666667\n",
      " 0.48888889 0.52222222 0.66111111 0.57777778 0.60555556 0.33888889\n",
      " 0.6        0.68888889 0.71111111 0.22777778 0.46666667 0.63333333\n",
      " 0.45555556 0.41666667 0.32222222 0.66666667 0.54444444 0.14444444\n",
      " 0.27222222 0.58333333 0.4        0.55       0.47222222 0.48333333\n",
      " 0.35       0.57777778 0.77222222 0.62777778 0.56111111 0.58333333\n",
      " 0.82777778 0.36111111 0.51666667 0.46666667 0.63888889 0.42777778\n",
      " 0.33333333 0.52777778 0.30555556 0.30555556 0.30555556 0.25555556\n",
      " 0.46666667 0.41111111 0.27777778 0.57777778 0.35555556 0.47222222\n",
      " 0.46111111 0.27777778 0.51111111 0.50555556 0.5        0.47222222\n",
      " 0.14444444 0.51111111 0.54444444 0.52777778 0.62222222 0.21111111\n",
      " 0.63888889 0.42222222 0.61111111 0.61111111 0.46111111 0.63333333\n",
      " 0.78888889 0.13333333 0.47222222 0.35       0.55       0.68333333\n",
      " 0.22777778 0.35       0.47777778 0.42777778 0.56666667 0.62222222\n",
      " 0.43333333 0.23333333 0.51666667 0.55555556 0.52222222 0.66111111\n",
      " 0.52222222 0.43888889 0.69444444 0.41666667 0.5        0.57222222\n",
      " 0.51111111 0.39444444 0.51666667 0.35555556 0.60555556 0.59444444\n",
      " 0.63333333 0.52777778 0.40555556 0.56111111 0.55555556 0.43333333\n",
      " 0.62777778 0.38888889 0.36666667 0.78333333 0.83888889 0.48888889\n",
      " 0.41111111 0.47222222 0.71111111 0.38888889 0.52222222 0.56666667\n",
      " 0.46111111 0.42222222 0.56111111 0.41111111 0.47222222 0.40555556\n",
      " 0.52222222 0.28888889 0.71111111 0.36666667 0.50555556 0.44444444\n",
      " 0.38888889 0.51666667 0.43333333 0.70555556 0.38888889 0.46111111\n",
      " 0.37222222 0.56666667 0.57222222 0.29444444 0.55       0.26111111\n",
      " 0.41666667 0.45       0.53333333 0.24444444 0.66666667 0.46666667\n",
      " 0.43333333 0.33888889 0.66111111 0.39444444 0.47777778 0.66111111\n",
      " 0.62222222 0.45       0.49444444 0.59444444 0.35555556 0.52777778\n",
      " 0.73888889 0.49444444 0.57777778 0.55555556 0.33333333 0.65\n",
      " 0.63333333 0.51666667 0.61111111 0.53333333 0.55       0.47777778\n",
      " 0.64444444 0.48333333 0.66111111 0.6        0.21111111 0.58888889\n",
      " 0.48888889 0.72777778 0.90555556 0.42222222 0.26666667 0.52777778\n",
      " 0.54444444 0.46666667 0.41666667 0.67777778 0.62777778 0.63333333\n",
      " 0.71666667 0.61666667 0.42222222 0.35555556 0.38333333 0.23888889\n",
      " 0.39444444 0.47222222 0.38888889 0.68888889 0.55       0.50555556\n",
      " 0.66111111 0.36111111 0.52777778 0.7        0.41666667 0.71666667\n",
      " 0.41666667 0.61666667 0.26111111 0.58888889 0.54444444 0.43888889\n",
      " 0.64444444 0.83333333 0.48333333 0.45555556 0.55555556 0.67222222\n",
      " 0.38333333 0.55       0.46111111 0.2        0.56111111 0.46111111\n",
      " 0.55555556 0.37777778 0.38888889 0.43333333 0.21111111 0.51666667\n",
      " 0.35555556 0.68888889 0.28888889 0.59444444 0.46666667 0.63333333\n",
      " 0.29444444 0.32777778 0.53333333 0.45       0.62777778 0.31666667\n",
      " 0.51666667 0.53333333 0.72777778 0.61111111 0.64444444 0.62777778\n",
      " 0.56666667 0.60555556 0.67222222 0.66666667 0.65555556 0.68333333\n",
      " 0.31111111 0.80555556 0.62222222 0.36111111 0.66666667 0.55555556\n",
      " 0.7        0.43888889 0.42777778 0.67777778 0.39444444 0.68333333\n",
      " 0.78333333 0.54444444 0.52777778 0.63888889 0.52222222 0.34444444\n",
      " 0.47222222 0.39444444 0.42777778 0.45555556 0.72777778 0.58333333\n",
      " 0.48888889 0.52222222 0.36111111 0.38333333 0.48888889 0.52777778\n",
      " 0.66666667 0.70555556 0.62777778 0.28333333 0.68888889 0.70555556\n",
      " 0.41111111 0.51111111 0.47222222 0.27777778 0.55       0.50555556\n",
      " 0.62777778 0.32777778 0.61666667 0.60555556 0.31666667 0.49444444\n",
      " 0.45555556 0.53333333 0.49444444 0.40555556 0.24444444 0.60555556\n",
      " 0.24444444 0.58888889 0.42222222 0.51666667 0.5        0.55\n",
      " 0.16111111 0.38888889 0.55       0.75       0.66111111 0.26111111\n",
      " 0.66111111 0.55       0.65       0.59444444 0.71666667 0.52777778\n",
      " 0.53888889 0.4        0.48888889 0.36111111 0.32777778 0.65555556\n",
      " 0.80555556 0.7        0.44444444 0.70555556 0.35555556 0.31666667\n",
      " 0.7        0.55       0.37222222 0.56666667 0.58888889 0.63888889\n",
      " 0.45       0.52777778 0.41666667 0.43333333 0.37777778 0.80555556\n",
      " 0.37222222 0.52222222 0.56666667 0.67777778 0.5        0.47222222\n",
      " 0.67222222 0.6        0.46666667 0.69444444 0.65555556 0.53888889\n",
      " 0.35555556 0.52777778 0.31111111 0.48888889 0.43888889 0.49444444\n",
      " 0.47777778 0.36111111 0.63888889 0.43333333 0.22222222 0.58333333\n",
      " 0.61666667 0.2        0.5        0.26666667 0.52222222 0.70555556\n",
      " 0.57222222 0.63888889 0.24444444 0.75       0.71666667 0.55555556\n",
      " 0.45555556 0.62777778 0.58888889 0.6        0.53333333 0.44444444\n",
      " 0.60555556 0.37777778 0.33333333 0.71111111 0.47777778 0.56111111\n",
      " 0.5        0.66666667 0.68888889 0.7        0.45555556 0.53333333\n",
      " 0.43888889 0.77777778 0.45555556 0.45555556 0.73333333 0.56111111\n",
      " 0.59444444 0.56666667 0.63888889 0.52777778 0.33888889 0.26666667\n",
      " 0.05       0.46111111 0.29444444 0.72222222 0.68888889 0.36111111\n",
      " 0.42222222 0.53888889 0.31666667 0.37777778 0.57777778 0.76666667\n",
      " 0.29444444 0.71666667 0.35       0.73333333 0.33888889 0.40555556\n",
      " 0.57222222 0.45555556 0.66111111 0.35555556 0.5        0.53333333\n",
      " 0.51111111 0.61111111 0.28888889 0.71666667 0.53333333 0.75\n",
      " 0.72777778 0.43333333 0.65       0.82777778 0.36666667 0.47777778\n",
      " 0.74444444 0.52222222 0.59444444 0.56666667 0.73333333 0.41111111\n",
      " 0.62777778 0.36666667 0.6        0.67777778 0.58888889 0.53888889\n",
      " 0.56111111 0.40555556 0.90555556 0.49444444 0.23333333 0.46666667\n",
      " 0.48333333 0.36666667 0.7        0.65555556 0.42777778 0.5\n",
      " 0.65       0.44444444 0.46111111 0.63888889 0.33333333 0.55\n",
      " 0.46111111 0.50555556 0.66111111 0.68888889 0.51111111 0.31111111\n",
      " 0.65555556 0.63333333 0.58888889 0.73888889 0.35555556 0.37222222\n",
      " 0.53333333 0.52222222 0.73333333 0.52222222 0.46111111 0.15\n",
      " 0.46666667 0.39444444 0.53333333 0.7        0.72777778 0.48333333\n",
      " 0.47222222 0.30555556 0.59444444 0.53333333 0.49444444 0.35555556\n",
      " 0.36666667 0.38888889 0.75       0.55       0.37222222 0.88333333\n",
      " 0.33333333 0.73333333 0.36666667 0.23888889 0.71666667 0.60555556\n",
      " 0.38888889 0.33888889 0.48888889 0.38888889 0.75       0.68888889\n",
      " 0.70555556 0.2        0.43888889 0.67777778 0.4        0.42777778\n",
      " 0.56666667 0.53888889 0.26111111 0.45       0.66666667 0.41666667\n",
      " 0.59444444 0.38888889 0.52777778 0.43333333 0.32222222 0.32777778\n",
      " 0.51111111 0.77222222 0.54444444 0.27222222 0.60555556 0.65555556\n",
      " 0.57777778 0.55       0.66111111 0.43888889 0.52777778 0.58333333\n",
      " 0.65555556 0.24444444 0.62222222 0.3        0.51666667 0.47222222\n",
      " 0.50555556 0.41111111 0.61111111 0.73333333 0.56666667 0.47222222\n",
      " 0.8        0.69444444 0.83333333 0.52222222 0.22222222 0.47777778\n",
      " 0.45       0.36111111 0.37222222 0.27777778 0.17222222 0.30555556\n",
      " 0.42222222 0.63888889 0.42777778 0.71666667 0.21666667 0.55555556\n",
      " 0.24444444 0.82222222 0.58888889 0.66111111 0.4        0.65555556\n",
      " 0.81111111 0.60555556 0.42777778 0.66111111 0.52777778 0.71111111\n",
      " 0.63333333 0.66111111 0.42222222 0.27222222 0.33333333 0.51111111\n",
      " 0.45       0.70555556 0.58888889 0.49444444 0.38333333 0.33888889\n",
      " 0.68888889 0.51111111 0.35555556 0.49444444 0.51111111 0.5\n",
      " 0.42222222 0.35       0.27222222 0.41666667 0.46111111 0.54444444\n",
      " 0.45       0.58888889 0.51111111 0.39444444 0.35       0.52777778\n",
      " 0.40555556 0.53888889 0.62777778 0.46666667 0.21666667 0.30555556\n",
      " 0.47777778 0.26666667 0.42222222 0.47222222 0.58888889 0.23333333\n",
      " 0.46111111 0.22777778 0.41111111 0.35555556 0.60555556 0.55\n",
      " 0.67777778 0.36111111 0.62222222 0.28888889 0.32777778 0.3\n",
      " 0.42222222 0.13888889 0.59444444 0.85555556 0.6        0.55\n",
      " 0.61666667 0.31666667 0.23888889 0.69444444 0.57777778 0.51111111\n",
      " 0.61666667 0.48333333 0.31666667 0.21666667 0.37777778 0.48888889\n",
      " 0.61666667 0.35555556 0.59444444 0.43333333 0.64444444 0.34444444\n",
      " 0.45555556 0.58888889 0.49444444 0.52777778] 0.005994005994005994\n"
     ]
    }
   ],
   "source": [
    "cv = model_selection.StratifiedKFold(5)\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('zv', feature_selection.VarianceThreshold()),\n",
    "  ('fa', decomposition.FactorAnalysis()),\n",
    "  ('clf', svm.SVC(kernel='linear', probability=False))\n",
    "])\n",
    "\n",
    "param_space = {\n",
    "  'fa__rotation': Categorical(['varimax']),\n",
    "  'fa__n_components': Integer(1, 10),\n",
    "  'clf__C': Real(1e-3, 1e3, 'log-uniform'),\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(pipe, param_space, cv=cv, n_jobs=1)\n",
    "\n",
    "def fit(X, y, feature_names):\n",
    "  # encode y as integers\n",
    "  y_encoder = preprocessing.LabelEncoder()\n",
    "  y = y_encoder.fit_transform(y)\n",
    "      \n",
    "  # test/train splits\n",
    "  train, test = model_selection.train_test_split(\n",
    "    range(len(X)),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    stratify=y,)\n",
    "      \n",
    "  progress_bar = tqdm(total=opt.total_iterations)\n",
    "\n",
    "  opt.fit(X[train], y[train],\n",
    "          callback = [\n",
    "            skopt.callbacks.DeadlineStopper(total_time=300),\n",
    "            lambda _: False if progress_bar.update() else False,\n",
    "  ])\n",
    "\n",
    "  progress_bar.close()\n",
    "  \n",
    "  # evaluate\n",
    "  score_train = opt.score(X[train], y[train])\n",
    "  score_test = opt.score(X[test], y[test])\n",
    "\n",
    "  # report scores and hyperparameters\n",
    "  print(f'train set score (roc_auc): {score_train:.2f}')\n",
    "  print(f'test set score (roc_auc): {score_test:.2f}')\n",
    "\n",
    "  # we don't have a hyperparameter so we pass 'pipe' instead of 'grid'\n",
    "  obs_score, perm_scores, p_value = model_selection.permutation_test_score(\n",
    "    opt.best_estimator_, X, y,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_permutations=1000,\n",
    "    n_jobs=-1, verbose=0)\n",
    "  \n",
    "  print(obs_score, perm_scores, p_value)\n",
    "\n",
    "for atlas in atlases:\n",
    "  for kind in connectivity_measures:\n",
    "    X, y, feature_names = load_connectivity(\n",
    "      parcellation=atlas,\n",
    "      kind=kind,\n",
    "      vectorize=False,\n",
    "      return_y=True,\n",
    "      only_diagonal=True,\n",
    "      return_feature_names=True,\n",
    "      discard_diagonal=True,\n",
    "      discard_cerebellum=False,)\n",
    "    \n",
    "    if len(X.shape) == 3:\n",
    "      # binarize\n",
    "      X_threshold = np.array([np.median(x, keepdims=True) + x.std(keepdims=True) for x in X])\n",
    "      X = np.where(np.abs(X) > X_threshold, 1, 0)\n",
    "\n",
    "      X = np.array([x[np.triu_indices_from(x, k=1)] for x in X])\n",
    "      feature_names = feature_names.values[np.triu_indices_from(feature_names.values, k=1)]\n",
    "\n",
    "      # remove zero-variance features\n",
    "      zv_mask = (X.std(axis=0) == 0)\n",
    "      X = X[:,~zv_mask]\n",
    "      feature_names = feature_names[~zv_mask]\n",
    "    \n",
    "    # fit the FA model\n",
    "    fit(X, y, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract network names from the @Dosenbach2010 atlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets as nilean_datasets\n",
    "\n",
    "atlas = nilean_datasets.fetch_coords_dosenbach_2010(legacy_format=False)\n",
    "labels = pd.concat(\n",
    "  [pd.DataFrame(v) for k, v in atlas.items() if k != 'description'], axis=1)\n",
    "labels.set_index(0, inplace=True)\n",
    "\n",
    "feature_network_names = labels.loc[feature_names, 'network']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign colors to the networks and their corresponding regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palt = dict(zip(\n",
    "  feature_network_names.unique(),\n",
    "  sns.color_palette('Set1', feature_network_names.nunique())))\n",
    "\n",
    "feature_network_colors = feature_network_names.apply(\n",
    "  lambda x: pd.Series((palt[x], x)))\n",
    "feature_network_colors.rename(columns={0:'color', 1:'network'}, inplace=True)\n",
    "feature_network_colors.index.name = 'region'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the Factor Analysis components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_comps = pd.DataFrame(\n",
    "  opt.best_estimator_.named_steps['fa'].components_,\n",
    "  columns=feature_network_names\n",
    ")\n",
    "\n",
    "sns.clustermap(fa_comps.T, figsize=(5,36),\n",
    "               col_cluster=False,\n",
    "               robust=True,\n",
    "               dendrogram_ratio=(0.2, 0.000001),\n",
    "               cbar_pos=(.96, .967, 0.01, 0.03),\n",
    "               row_colors=feature_network_colors['color'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "\n",
    "-[ ] TODO: replicate https://www.frontiersin.org/articles/10.3389/fnhum.2014.00425/full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIXME: Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "pipe.fit(X, y)\n",
    "perm_imp_result = permutation_importance(pipe, X, y, \n",
    "                                         n_repeats=100,\n",
    "                                         scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "perm_sorted_idx = perm_imp_result.importances_mean.argsort()\n",
    "\n",
    "# sns.boxplot(\n",
    "#     result.importances[perm_sorted_idx].T,\n",
    "#     vert=False,\n",
    "#     labels=data.feature_names[perm_sorted_idx],\n",
    "# )\n",
    "\n",
    "\n",
    "perm_imp_result.importances[perm_sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "corr = spearmanr(X).correlation\n",
    "\n",
    "# Ensure the correlation matrix is symmetric\n",
    "corr = (corr + corr.T) / 2\n",
    "np.fill_diagonal(corr, 1)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10, 10))\n",
    "\n",
    "# We convert the correlation matrix to a distance matrix before performing\n",
    "# hierarchical clustering using Ward's linkage.\n",
    "distance_matrix = 1 - np.abs(corr)\n",
    "dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "dendro = hierarchy.dendrogram(\n",
    "    dist_linkage, labels=feature_names.tolist(), ax=ax1, leaf_rotation=90\n",
    ")\n",
    "\n",
    "dendro_idx = np.arange(0, len(dendro[\"ivl\"]))\n",
    "\n",
    "\n",
    "\n",
    "ax2.imshow(corr[dendro[\"leaves\"], :][:, dendro[\"leaves\"]])\n",
    "ax2.set_xticks(dendro_idx)\n",
    "ax2.set_yticks(dendro_idx)\n",
    "ax2.set_xticklabels(dendro[\"ivl\"], rotation=\"vertical\")\n",
    "ax2.set_yticklabels(dendro[\"ivl\"])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "cluster_ids = hierarchy.fcluster(dist_linkage, 1, criterion=\"distance\")\n",
    "cluster_id_to_feature_ids = defaultdict(list)\n",
    "for idx, cluster_id in enumerate(cluster_ids):\n",
    "    cluster_id_to_feature_ids[cluster_id].append(idx)\n",
    "selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
    "\n",
    "X_clustered = X[:, selected_features]\n",
    "\n",
    "# Permmutation Importance\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "grid.fit(X_clustered[train], y[train])\n",
    "perm_imp_result = permutation_importance(grid, X_clustered[test], y[test],\n",
    "                                         scoring='roc_auc',\n",
    "                                         n_repeats=100)\n",
    "\n",
    "sorted_idx = perm_imp_result.importances_mean.argsort()[::-1][:10][::-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.boxplot(\n",
    "    perm_imp_result.importances[sorted_idx].T,\n",
    "    labels = feature_names[np.array(selected_features)[sorted_idx]],\n",
    "    vert=False,\n",
    ")\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34f04479ffaeb5c00adb9e28a92647dce776275bf5ee61de72266754f4451f1a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('acnets')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
