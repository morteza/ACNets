{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extracts individual connectivity matrices of the networks defined in [@dosenbach2007], [@dosenbach2010], and [@difumo2018] atlases. The connectivity matrix, of shape $N_{\\text{subjects}} \\times N_{\\text{regions}} \\times N_{\\text{regions}}$, will be stored in annotated NetCDF4 files in the following paths:\n",
    "\n",
    "- `data/julia2018_resting/connectivity_dosenbach2007.nc`.\n",
    "- `data/julia2018_resting/connectivity_dosenbach2010.nc`.\n",
    "- `data/julia2018_resting/connectivity_difumo_64_2.nc`.\n",
    "- `data/julia2018_resting/connectivity_difumo_128_2.nc`.\n",
    "- `data/julia2018_resting/connectivity_difumo_1024_2.nc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We require the following packages: `nilearn`, `XArray`, and `NetCDF4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from nilearn import connectome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the time-series of the cognitive control network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = dict.fromkeys([\n",
    "  'dosenbach2007',\n",
    "  'dosenbach2010',\n",
    "  # 'difumo_64_2',\n",
    "  # 'difumo_128_2',\n",
    "  # 'difumo_1024_2'\n",
    "  ], None)\n",
    "\n",
    "# load the datasets\n",
    "DATASETS = {\n",
    "  ds_name: xr.open_dataset(f'data/julia2018_resting/timeseries_{ds_name}.nc')\n",
    "  for ds_name in DATASETS.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit connectivity matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_timeseries(timeseries: xr.DataArray) -> Tuple[np.ndarray, list[np.ndarray]]:\n",
    "  \"\"\"Discard subjects with missing resting time-series.\n",
    "  \n",
    "  Returns:\n",
    "    - mask : np.ndarray\n",
    "      boolean array of shape (n_subjects, n_times)\n",
    "    - valid_timeseries : list[np.ndarray]\n",
    "      list of valid time-series, one item per subject.\n",
    "  \"\"\"\n",
    "\n",
    "  missing_mask = timeseries.isnull().all(dim=['region','timestep'])\n",
    "  valid_timeseries = [ts.T for ts in timeseries.values[~missing_mask]]\n",
    "  return missing_mask, valid_timeseries\n",
    "\n",
    "\n",
    "# some subjects are missing resting time-series, so we need to filter them out.\n",
    "timeseries = {\n",
    "  key: get_valid_timeseries(ds['timeseries'])\n",
    "  for key, ds in DATASETS.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dosenbach2007: 100%|██████████| 5/5 [00:00<00:00, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dosenbach2007 connectivity saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dosenbach2010: 100%|██████████| 5/5 [00:02<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dosenbach2010 connectivity saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate over atlases and connectivity kinds and calculate them\n",
    "\n",
    "conn_kinds = ['covariance','correlation', 'partial correlation', 'tangent', 'precision']\n",
    "\n",
    "for ds_name, (missing_mask, valid_timeseries) in timeseries.items():\n",
    "  \n",
    "  dataset = DATASETS[ds_name]\n",
    "  dataset.attrs['description'] = f'Resting state connectivity matrices for {ds_name}'\n",
    "  missing_indices = np.flatnonzero(missing_mask)\n",
    "  \n",
    "  for kind in tqdm(conn_kinds, desc=ds_name):\n",
    "    \n",
    "    # calculate connectivity measure\n",
    "    cm = connectome.ConnectivityMeasure(kind=kind, vectorize=False)\n",
    "    conn = cm.fit_transform(valid_timeseries)\n",
    "    \n",
    "    # now refill the places of the missing time-series with nan values\n",
    "    nan_insertion_indices = missing_indices - np.arange(missing_indices.shape[0])\n",
    "    conn = np.insert(conn, nan_insertion_indices, np.full_like(conn[0], np.nan), axis=0)\n",
    "\n",
    "    # DEBUG: just to make sure missing values are handled correctly\n",
    "    assert np.equal(np.isnan(conn).all(axis=(1,2)), missing_mask).all()\n",
    "\n",
    "    # add to the dataset\n",
    "    ds_key_name = kind.replace(' ', '_') + '_connectivity'\n",
    "    dataset[ds_key_name] = xr.DataArray(conn, dims=['subject', 'region', 'region'])\n",
    "\n",
    "  # now store the dataset\n",
    "  dataset.to_netcdf(f'data/julia2018_resting/connectivity_{ds_name}.nc', engine='netcdf4')\n",
    "  print(f'{ds_name} connectivity saved successfully.')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34f04479ffaeb5c00adb9e28a92647dce776275bf5ee61de72266754f4451f1a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('acnets')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
