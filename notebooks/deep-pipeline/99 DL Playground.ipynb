{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Playground\n",
    "\n",
    "We are interested in the following features:\n",
    "\n",
    "- H1: region-averaged time-series\n",
    "- H2: region-level connectivities (from H1, optional: triu-k1)\n",
    "- H3: network-averaged time-series (from H1)\n",
    "- H4: network connectivity (from H3, optional: triu-k1)\n",
    "- H5: networks connectivity (from H2, optional: triu-k0)\n",
    "\n",
    "> Note that we are not going to take the upper triangular part of the connectivity matrix and full matrices are used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the cosine distance between all pairs of time series\n",
    "\n",
    "import numpy as np\n",
    "from scipy import spatial, linalg, stats\n",
    "\n",
    "n_timepoints = 652\n",
    "n_regions = 6\n",
    "timeseries = np.random.rand(n_regions, n_timepoints)\n",
    "\n",
    "dist = spatial.distance.pdist(timeseries, 'correlation')\n",
    "\n",
    "# np.isclose(1 - dist, pearson_corr[np.triu_indices(n_regions, k=1)])\n",
    "\n",
    "pearson_corr = np.corrcoef(timeseries)\n",
    "spearman_corr = stats.spearmanr(timeseries, axis=1).correlation\n",
    "\n",
    "corr_inv = linalg.inv(spearman_corr)\n",
    "\n",
    "pcorr = np.zeros_like(spearman_corr)\n",
    "for i in range(corr_inv.shape[0]):\n",
    "    for j in range(corr_inv.shape[1]):\n",
    "        if i != j:  # off-diagonal\n",
    "            pcorr[i, j] = -corr_inv[i, j] / np.sqrt(corr_inv[i, i] * corr_inv[j, j])\n",
    "\n",
    "pcorr[np.diag_indices_from(pcorr)] = 1.0  # set diagonal to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "\n",
    "from src.acnets.deep import ACNetsDataModule, MultiHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule = ACNetsDataModule(atlas='dosenbach2010', kind='partial correlation', batch_size=8)\n",
    "datamodule.setup()\n",
    "\n",
    "n_regions = datamodule.train[0][0].shape[1]\n",
    "n_networks = datamodule.train[0][2].shape[1]\n",
    "\n",
    "# DEBUG single epoch, one train/test split\n",
    "model = MultiHeadModel(n_regions, n_networks, n_embeddings=32)\n",
    "trainer = pl.Trainer(accelerator='auto',\n",
    "                     max_epochs=10000,\n",
    "                     accumulate_grad_batches=3,\n",
    "                     gradient_clip_val=.5,\n",
    "                     log_every_n_steps=3,\n",
    "                     callbacks=[RichProgressBar()])\n",
    "trainer.fit(model, datamodule)\n",
    "trainer.test(model, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
