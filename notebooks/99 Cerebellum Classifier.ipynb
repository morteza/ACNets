{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cerebellum Connectivity Classifier\n",
    "\n",
    "Steps:\n",
    "1. Load the data\n",
    "2. Extract the cerebellum features (from DiFuMo atlas)\n",
    "2. Fit a SVM + HPO\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Cerebellum activities from the DiFuMo atlas.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Classification output: Participant's label, either AVGP or NVGP.\n",
    "- Results:\n",
    "  - `models/cerebellum_classifier_*.nc`\n",
    "\n",
    "\n",
    "## Requirements\n",
    "\n",
    "To run this notebook, you need to activate `acnets` environment using `conda activate acnets`.\n",
    "\n",
    "# TODO:\n",
    "- Add support for cerebellum in the ConnectivityPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 0. SETUP\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import scipy.stats as st\n",
    "import xarray as xr\n",
    "from src.acnets.pipeline import CerebellumPipeline, ConnectivityVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import (GridSearchCV, StratifiedShuffleSplit,\n",
    "                                     cross_val_score, learning_curve,\n",
    "                                     permutation_test_score)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "atlas = datasets.fetch_atlas_difumo(\n",
    "    dimension=256,  # 64, 128, 256, 512, 1024\n",
    "    resolution_mm=2,\n",
    "    legacy_format=False)\n",
    "\n",
    "atlas.labels.query('difumo_names.str.lower().str.contains(\"cerebellum\")').shape\n",
    "# atlas.labels['yeo_networks17'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 0.1. PARAMETERS\n",
    "\n",
    "CV = StratifiedShuffleSplit(n_splits=100, test_size=8)\n",
    "N_PERMUTATIONS = 10\n",
    "N_TOP_MODELS = 5\n",
    "\n",
    "MODELS_DIR= Path('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 1. DATA\n",
    "\n",
    "subjects = CerebellumPipeline().transform('all').coords['subject'].values\n",
    "groups = [s[:4] for s in subjects]  # AVGP or NVGP\n",
    "\n",
    "X = subjects.reshape(-1, 1)\n",
    "\n",
    "y_encoder = LabelEncoder()\n",
    "y = y_encoder.fit_transform(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPARE OUTPUT\n",
    "\n",
    "n_cv_fold = int(X.shape[0] / CV.test_size)\n",
    "\n",
    "model_output_name = ('cerebellum'\n",
    "                     '_classifier-SVML1'\n",
    "                     'scoring-accuracy'\n",
    "                     f'_top-{N_TOP_MODELS}'\n",
    "                     f'_cv-{CV.get_n_splits()}x{n_cv_fold}fold.nc'\n",
    "                     )\n",
    "\n",
    "OUTPUT_PATH = MODELS_DIR / model_output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. PIPELINE\n",
    "\n",
    "pipe  = Pipeline([\n",
    "    ('connectivity', CerebellumPipeline()),\n",
    "    ('vectorize', ConnectivityVectorizer()),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('zerovar', VarianceThreshold()),\n",
    "    ('select', SelectFromModel(LinearSVC(penalty='l1', dual=False, max_iter=10000), max_features=10)),\n",
    "    ('clf', LinearSVC(penalty='l1', dual=False, max_iter=10000))\n",
    "])\n",
    "\n",
    "# DEBUG\n",
    "pipe.fit(X, y).score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/wjvd5/download ...\n",
      "Downloading data from https://osf.io/wjvd5/download ...\n",
      "Downloading data from https://osf.io/wjvd5/download ...\n",
      "Downloading data from https://osf.io/wjvd5/download ...\n",
      "Downloading data from https://osf.io/wjvd5/download ...\n",
      "Downloading data from https://osf.io/wjvd5/download ...\n",
      "Downloading data from https://osf.io/wjvd5/download ...\n",
      "Downloading data from https://osf.io/wjvd5/download ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (2 seconds, 0 min)\n",
      "Extracting data from /home/morteza/nilearn_data/difumo_atlases/21d764636e41d335113bb464d8fdcb60/download..... done.\n"
     ]
    }
   ],
   "source": [
    "# 2.1. VERIFY THE MODEL\n",
    "pipe.set_params(connectivity__difumo_dimension=128, connectivity__kind='tangent', connectivity__agg_networks=True)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y,\n",
    "                         cv=CV,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=-1)\n",
    "bootstrap_ci = st.bootstrap(scores.reshape(1,-1), np.mean)\n",
    "scores.mean(), scores.std(), bootstrap_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 100 folds for each of 5 candidates, totalling 500 fits\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 3. HPO: GRID SEARCH\n",
    "\n",
    "param_grid = {\n",
    "    'connectivity__difumo_dimension': [64, 128, 256, 512, 1024],\n",
    "    # 'connectivity__atlas': ['seitzman2018'],\n",
    "    'connectivity__kind': ['tangent'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=CV,\n",
    "    verbose=1,\n",
    "    scoring='accuracy')\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "print('best estimator:', grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# 3.1. STORE GRID SEARCH RESULTS\n",
    "\n",
    "#STORE pd.DataFrame(grid.cv_results_).set_index('params')\n",
    "#STORE grid.scoring, grid.cv.test_size,  grid.cv.n_splits, n_subjects\n",
    "grid_results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "grid_results['grid_model_name'] = grid_results['params'].apply(lambda x: ' '.join(x.values()))\n",
    "grid_results.set_index('grid_model_name', inplace=True)\n",
    "grid_results.drop(columns=['params'], inplace=True)\n",
    "\n",
    "ds_grid = grid_results.to_xarray()\n",
    "ds_grid['scoring'] = grid.scoring\n",
    "ds_grid['cv_test_size'] = CV.test_size\n",
    "ds_grid['cv_n_splits'] = CV.n_splits\n",
    "ds_grid['n_subjects'] = len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# 4. PERMUTATION TEST (SHUFFLE Y)\n",
    "\n",
    "\n",
    "perm_scores_agg = []\n",
    "cv_scores_agg = []\n",
    "pvalues = []\n",
    "model_names = []\n",
    "\n",
    "# sort by rank and take top n_top_models\n",
    "top_models = pd.DataFrame(grid.cv_results_).sort_values('rank_test_score')[:N_TOP_MODELS].loc[:,'params'].to_list()\n",
    "\n",
    "for p in tqdm(top_models):\n",
    "    model_name = ' '.join(p.values())\n",
    "    \n",
    "    pipe.set_params(**p)\n",
    "\n",
    "    # break if it's a low score\n",
    "\n",
    "    _, perm_scores, pvalue = permutation_test_score(pipe, X, y,\n",
    "                                                    scoring='accuracy',\n",
    "                                                    n_permutations=N_PERMUTATIONS,\n",
    "                                                    cv=4,\n",
    "                                                    n_jobs=-1, verbose=0)\n",
    "\n",
    "    cv_scores = cross_val_score(pipe, X, y,\n",
    "                                cv=CV,\n",
    "                                scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    perm_scores_agg.append(perm_scores)\n",
    "    cv_scores_agg.append(cv_scores)\n",
    "    pvalues.append(pvalue)\n",
    "    model_names.append(model_name)\n",
    "\n",
    "ds_perm = xr.Dataset({\n",
    "    'perm_scores': (('model_name', 'permutation_dim'), perm_scores_agg),\n",
    "    'cv_scores': (('model_name', 'cv_dim'), cv_scores_agg),\n",
    "    'pvalue': (('model_name'), pvalues)},\n",
    "    coords={'model_name': model_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# 5. FEATURE IMPORTANCE (SHUFFLE X)\n",
    "\n",
    "importances_agg = []\n",
    "\n",
    "for p in top_models:\n",
    "    model_name = ' '.join(p.values())\n",
    "\n",
    "    pipe.set_params(**p)\n",
    "\n",
    "    X_conn = pipe[:2].transform(X)\n",
    "    feature_names = pipe[:2].get_feature_names_out()\n",
    "\n",
    "    importances = []\n",
    "\n",
    "    for train, test in tqdm(CV.split(X,y), total=CV.get_n_splits(X,y)):\n",
    "        pipe.fit(X[train], y[train])\n",
    "\n",
    "        results = permutation_importance(pipe[2:], X_conn[test], y[test],\n",
    "                                        scoring=grid.scoring,\n",
    "                                        n_jobs=1)\n",
    "        importances.append(results.importances.T)\n",
    "\n",
    "    feature_dim_name = f'{model_name.split(\" \")[0]}_feature'\n",
    "\n",
    "    importances_ds = xr.Dataset({\n",
    "        f'{model_name} importances': (('permutation_importance_num', feature_dim_name), np.vstack(importances))},\n",
    "        coords={feature_dim_name: feature_names}\n",
    "    )\n",
    "\n",
    "    importances_agg.append(importances_ds)\n",
    "    \n",
    "    # sort by mean importance\n",
    "    # importances = pd.DataFrame(np.vstack(importances), columns=feature_names)\n",
    "    # sorted_columns = importances.mean(axis=0).sort_values(ascending=False).index\n",
    "    # importances = importances[sorted_columns]\n",
    "\n",
    "ds_imp = xr.merge(importances_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "# 8. STORE RESULTS\n",
    "\n",
    "results = xr.merge([\n",
    "    {'X': xr.DataArray(X.flatten(), dims=['subject'])},\n",
    "    {'y': xr.DataArray(y_encoder.inverse_transform(y), dims='subject')},\n",
    "    {'y_classes': y_encoder.classes_},\n",
    "    ds_grid, ds_imp, ds_perm])\n",
    "\n",
    "with open(OUTPUT_PATH, 'wb') as f:\n",
    "    results.to_netcdf(f, engine='scipy')\n",
    "    results.close()\n",
    "\n",
    "results = xr.open_dataset(OUTPUT_PATH, engine='scipy').load()\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('acnets')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27337377eeae3c8189a7b021b93003f903d6e200a1ea36bbed16bbe086d62899"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
