{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cerebellum Connectivity Classifier\n",
    "\n",
    "Steps:\n",
    "1. Load the data\n",
    "2. Extract the cerebellum features (from DiFuMo atlas)\n",
    "2. Fit a SVM + HPO\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Cerebellum activities from the DiFuMo atlas.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Classification output: Participant's label, either AVGP or NVGP.\n",
    "- Results:\n",
    "  - `models/cerebellum_classifier_*.nc`\n",
    "\n",
    "\n",
    "## Requirements\n",
    "\n",
    "To run this notebook, you need to activate `acnets` environment using `conda activate acnets`.\n",
    "\n",
    "# TODO:\n",
    "- Add support for cerebellum in the ConnectivityPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 0. SETUP\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import scipy.stats as st\n",
    "import xarray as xr\n",
    "from src.acnets.pipeline import CerebellumPipeline, ConnectivityVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import (GridSearchCV, StratifiedShuffleSplit,\n",
    "                                     cross_val_score, learning_curve,\n",
    "                                     permutation_test_score)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import faulthandler\n",
    "\n",
    "\n",
    "faulthandler.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 0.1. PARAMETERS\n",
    "\n",
    "CV = StratifiedShuffleSplit(n_splits=5, test_size=8)\n",
    "N_PERMUTATIONS = 10\n",
    "N_TOP_MODELS = 5\n",
    "\n",
    "MODELS_DIR= Path('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 1. DATA\n",
    "\n",
    "subjects = CerebellumPipeline().transform('all').coords['subject'].values\n",
    "groups = [s[:4] for s in subjects]  # AVGP or NVGP\n",
    "\n",
    "X = subjects.reshape(-1, 1)\n",
    "\n",
    "y_encoder = LabelEncoder()\n",
    "y = y_encoder.fit_transform(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPARE OUTPUT\n",
    "\n",
    "n_cv_fold = int(X.shape[0] / CV.test_size)\n",
    "\n",
    "model_output_name = ('cerebellum'\n",
    "                     '_classifier-SVML1'\n",
    "                     '_scoring-accuracy'\n",
    "                     f'_top-{N_TOP_MODELS}'\n",
    "                     f'_cv-{CV.get_n_splits()}x{n_cv_fold}fold.nc5'\n",
    "                     )\n",
    "\n",
    "OUTPUT_PATH = MODELS_DIR / model_output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252e2fe3e3d849f6bb321afbe54faf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7436b84eb7bf4517a6be10a4926719dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resolution</th>\n",
       "      <th>max_features</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.65625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resolution  max_features  train_accuracy\n",
       "0          64             1         0.65625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d42d1a079f74020b500dc933c990ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resolution</th>\n",
       "      <th>max_features</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resolution  max_features  train_accuracy\n",
       "0         128             1             1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ac24a14717440686f49d8c9877058d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resolution</th>\n",
       "      <th>max_features</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resolution  max_features  train_accuracy\n",
       "0         256             1             1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f1a2e89591482993ecaaa837aa2759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resolution</th>\n",
       "      <th>max_features</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resolution  max_features  train_accuracy\n",
       "0         512             1             1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e569e0292f08440790fed5866600fac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resolution</th>\n",
       "      <th>max_features</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resolution  max_features  train_accuracy\n",
       "0        1024             1             1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. PIPELINE\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "pipe  = Pipeline([\n",
    "    ('connectivity', CerebellumPipeline(kind='precision')),\n",
    "    ('vectorize', ConnectivityVectorizer()),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('zerovar', VarianceThreshold()),\n",
    "    ('pca', PCA(n_components=0.99)),\n",
    "    # ('select', SelectFromModel(LinearSVC(penalty='l2', max_iter=1000),\n",
    "    #                         max_features=lambda x: min(10, x.shape[1]))),\n",
    "    ('clf', LinearSVC(penalty='l1', dual=False, max_iter=10000))\n",
    "    # ('clf', SVC(kernel='linear'))\n",
    "\n",
    "])\n",
    "\n",
    "for res in (pbar1 := tqdm([64, 128, 256, 512, 1024])):\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    pbar1.set_description(f\"DiFuMo_{res}\")\n",
    "    for max_features in (pbar2 := tqdm(range(1, 2))):\n",
    "        pbar2.set_description(f\"[DiFuMo_{res}] {max_features} features\")\n",
    "\n",
    "        pipe.set_params(connectivity__atlas_dimension=res)#, select__max_features=max_features)\n",
    "\n",
    "        # DEBUG\n",
    "        score = pipe.fit(X, y).score(X, y)  # expects 1.0\n",
    "        scores.append([res, max_features, score])\n",
    "    scores = pd.DataFrame(scores, columns=['resolution', 'max_features', 'train_accuracy'])\n",
    "    display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   8.2s\n",
      "[CV] END .................................................... total time=   8.3s\n",
      "[CV] END .................................................... total time=   8.3s\n",
      "[CV] END .................................................... total time=   8.3s\n",
      "[CV] END .................................................... total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   2 out of   5 | elapsed:   12.3s remaining:   18.5s\n",
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   12.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   12.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.55,\n",
       " 0.1274754878398196,\n",
       " BootstrapResult(confidence_interval=ConfidenceInterval(low=0.45, high=0.675), bootstrap_distribution=array([0.65 , 0.625, 0.575, ..., 0.65 , 0.5  , 0.575]), standard_error=0.05689838904357655))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1. verify the cv mean/ci of the model\n",
    "\n",
    "pipe.set_params(connectivity__atlas_dimension=128, connectivity__kind='tangent', connectivity__agg_networks=False)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y,\n",
    "                         cv=CV,\n",
    "                         scoring='accuracy',\n",
    "                         verbose=2,\n",
    "                         n_jobs=-2)\n",
    "bootstrap_ci = st.bootstrap(scores.reshape(1,-1), np.mean)\n",
    "scores.mean(), scores.std(), bootstrap_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END connectivity__atlas_dimension=128, connectivity__kind=precision; total time=  23.5s\n",
      "[CV] END connectivity__atlas_dimension=128, connectivity__kind=precision; total time=  23.5s\n",
      "[CV] END connectivity__atlas_dimension=128, connectivity__kind=precision; total time=  23.5s\n",
      "[CV] END connectivity__atlas_dimension=128, connectivity__kind=precision; total time=  23.6s\n",
      "[CV] END connectivity__atlas_dimension=128, connectivity__kind=tangent; total time=  23.7s\n",
      "[CV] END connectivity__atlas_dimension=128, connectivity__kind=tangent; total time=  38.2s\n",
      "[CV] END connectivity__atlas_dimension=128, connectivity__kind=precision; total time=  38.3s\n",
      "[CV] END connectivity__atlas_dimension=128, connectivity__kind=tangent; total time=  38.4s\n",
      "[CV] END connectivity__atlas_dimension=128, connectivity__kind=tangent; total time=  38.4s\n",
      "[CV] END connectivity__atlas_dimension=128, connectivity__kind=tangent; total time=  38.4s\n",
      "[CV] END connectivity__atlas_dimension=1024, connectivity__kind=tangent; total time= 4.3min\n",
      "[CV] END connectivity__atlas_dimension=1024, connectivity__kind=precision; total time= 4.1min\n",
      "[CV] END connectivity__atlas_dimension=1024, connectivity__kind=tangent; total time= 4.1min\n",
      "[CV] END connectivity__atlas_dimension=1024, connectivity__kind=tangent; total time= 4.1min\n",
      "[CV] END connectivity__atlas_dimension=1024, connectivity__kind=tangent; total time= 4.1min\n",
      "[CV] END connectivity__atlas_dimension=1024, connectivity__kind=tangent; total time= 4.1min\n",
      "[CV] END connectivity__atlas_dimension=1024, connectivity__kind=precision; total time= 3.8min\n",
      "[CV] END connectivity__atlas_dimension=1024, connectivity__kind=precision; total time= 3.8min\n",
      "[CV] END connectivity__atlas_dimension=1024, connectivity__kind=precision; total time= 3.8min\n",
      "[CV] END connectivity__atlas_dimension=1024, connectivity__kind=precision; total time= 3.8min\n",
      "best estimator: Pipeline(steps=[('connectivity',\n",
      "                 CerebellumPipeline(agg_networks=False, atlas_dimension=128)),\n",
      "                ('vectorize', ConnectivityVectorizer()),\n",
      "                ('scale', StandardScaler()), ('zerovar', VarianceThreshold()),\n",
      "                ('pca', PCA(n_components=0.99)),\n",
      "                ('clf', LinearSVC(dual=False, max_iter=10000, penalty='l1'))])\n"
     ]
    }
   ],
   "source": [
    "# 3. HPO: GRID SEARCH\n",
    "\n",
    "param_grid = {\n",
    "    'connectivity__atlas_dimension': [128, 1024],\n",
    "    # 'connectivity__atlas': ['seitzman2018'],\n",
    "    'connectivity__kind': ['tangent', 'precision'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=CV,\n",
    "    verbose=2,\n",
    "    n_jobs=-2,\n",
    "    scoring='accuracy')\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "print('best estimator:', grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# 3.1. STORE GRID SEARCH RESULTS\n",
    "\n",
    "#STORE pd.DataFrame(grid.cv_results_).set_index('params')\n",
    "#STORE grid.scoring, grid.cv.test_size,  grid.cv.n_splits, n_subjects\n",
    "grid_results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "grid_results['grid_model_name'] = grid_results['params'].apply(lambda x: [str(xx) for xx in x.values()]).apply(lambda x: ' '.join(x))\n",
    "grid_results.set_index('grid_model_name', inplace=True)\n",
    "grid_results.drop(columns=['params'], inplace=True)\n",
    "\n",
    "ds_grid = grid_results.to_xarray()\n",
    "ds_grid['scoring'] = grid.scoring\n",
    "ds_grid['cv_test_size'] = CV.test_size\n",
    "ds_grid['cv_n_splits'] = CV.n_splits\n",
    "ds_grid['n_subjects'] = len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# 4. PERMUTATION TEST (SHUFFLE Y)\n",
    "\n",
    "\n",
    "perm_scores_agg = []\n",
    "cv_scores_agg = []\n",
    "pvalues = []\n",
    "model_names = []\n",
    "\n",
    "# sort by rank and take top n_top_models\n",
    "top_models = pd.DataFrame(grid.cv_results_).sort_values('rank_test_score')[:N_TOP_MODELS].loc[:,'params'].to_list()\n",
    "\n",
    "for p in tqdm(top_models):\n",
    "    model_name = ' '.join([str(pp) for pp in p.values()])\n",
    "    \n",
    "    pipe.set_params(**p)\n",
    "\n",
    "    # break if it's a low score\n",
    "\n",
    "    _, perm_scores, pvalue = permutation_test_score(pipe, X, y,\n",
    "                                                    scoring='accuracy',\n",
    "                                                    n_permutations=N_PERMUTATIONS,\n",
    "                                                    cv=CV,\n",
    "                                                    n_jobs=-2, verbose=2)\n",
    "\n",
    "    cv_scores = cross_val_score(pipe, X, y,\n",
    "                                cv=CV,\n",
    "                                scoring='accuracy', n_jobs=-2)\n",
    "\n",
    "    perm_scores_agg.append(perm_scores)\n",
    "    cv_scores_agg.append(cv_scores)\n",
    "    pvalues.append(pvalue)\n",
    "    model_names.append(model_name)\n",
    "\n",
    "ds_perm = xr.Dataset({\n",
    "    'perm_scores': (('model_name', 'permutation_dim'), perm_scores_agg),\n",
    "    'cv_scores': (('model_name', 'cv_dim'), cv_scores_agg),\n",
    "    'pvalue': (('model_name'), pvalues)},\n",
    "    coords={'model_name': model_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# 5. FEATURE IMPORTANCE (SHUFFLE X)\n",
    "\n",
    "importances_agg = []\n",
    "\n",
    "for p in top_models:\n",
    "    model_name = ' '.join([str(pp) for pp in p.values()])\n",
    "\n",
    "    pipe.set_params(**p)\n",
    "\n",
    "    X_conn = pipe[:2].transform(X)\n",
    "    feature_names = pipe[:2].get_feature_names_out()\n",
    "\n",
    "    importances = []\n",
    "\n",
    "    for train, test in tqdm(CV.split(X,y), total=CV.get_n_splits(X,y)):\n",
    "        pipe.fit(X[train], y[train])\n",
    "\n",
    "        results = permutation_importance(pipe[2:], X_conn[test], y[test],\n",
    "                                        scoring=grid.scoring,\n",
    "                                        n_jobs=-1)\n",
    "        importances.append(results.importances.T)\n",
    "\n",
    "    feature_dim_name = f'{model_name.split(\" \")[0]}_feature'\n",
    "\n",
    "    importances_ds = xr.Dataset({\n",
    "        f'{model_name} importances': (('permutation_importance_num', feature_dim_name), np.vstack(importances))},\n",
    "        coords={feature_dim_name: feature_names}\n",
    "    )\n",
    "\n",
    "    importances_agg.append(importances_ds)\n",
    "    \n",
    "    # sort by mean importance\n",
    "    # importances = pd.DataFrame(np.vstack(importances), columns=feature_names)\n",
    "    # sorted_columns = importances.mean(axis=0).sort_values(ascending=False).index\n",
    "    # importances = importances[sorted_columns]\n",
    "\n",
    "ds_imp = xr.merge(importances_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "# 8. STORE RESULTS\n",
    "\n",
    "results = xr.merge([\n",
    "    {'X': xr.DataArray(X.flatten(), dims=['subject'])},\n",
    "    {'y': xr.DataArray(y_encoder.inverse_transform(y), dims='subject')},\n",
    "    {'y_classes': y_encoder.classes_},\n",
    "    ds_grid, ds_imp, ds_perm])\n",
    "\n",
    "with open(OUTPUT_PATH, 'wb') as f:\n",
    "    results.to_netcdf(f, engine='h5netcdf')\n",
    "    results.close()\n",
    "\n",
    "results = xr.open_dataset(OUTPUT_PATH, engine='scipy').load()\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('acnets')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27337377eeae3c8189a7b021b93003f903d6e200a1ea36bbed16bbe086d62899"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
