{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Pairwise Interactions (SPIs)\n",
    "\n",
    "This notebooks extracts 216 connectivity measures using the `pyspi` package, and then train a AVGPvsNVGP classifier using the connectivity features.\n",
    "\n",
    "**:warning: Warning:** This notebook requires packages that are not compatible with the current version of Python. To run this notebook, you need to create a separate conda environment using the following command:\n",
    "\n",
    "```bash\n",
    "mamba create -n pyspi python=3.9 octave openjdk\n",
    "mamba activate pyspi\n",
    "pip install -U pyspi scikit-learn xgboost xarray h5netcdf\n",
    "```\n",
    "\n",
    "\n",
    "## Outputs\n",
    "\n",
    "`data/Julia2018/spis_{atlas}_{process_type}_fast.csv`: The extracted SPIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, display\n",
    "from tqdm.notebook import tqdm\n",
    "import xarray as xr\n",
    "from pyspi.calculator import CalculatorFrame\n",
    "from pyspi.data import Data\n",
    "import pandas as pd\n",
    "from src.multimodal.preprocessing import TimeseriesAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "atlas = 'dosenbach2010'\n",
    "tsagg_strategy = 'network'  # time-series aggregation strategy\n",
    "\n",
    "# we only aggregate the region-wise timeseries into network-wise timeseries\n",
    "preproc_pipe = TimeseriesAggregator(strategy=tsagg_strategy)\n",
    "\n",
    "with xr.open_dataset(f'data/Julia2018/timeseries_{atlas}.nc5') as ds:\n",
    "    ds.load()\n",
    "    ds = preproc_pipe.fit_transform(ds)\n",
    "\n",
    "datasets = []\n",
    "process_type = ds['timeseries'].dims[-1]\n",
    "process_names = ds.coords[process_type].values\n",
    "for subject in ds.coords['subject'].values:\n",
    "    ts = ds.sel(subject=subject)['timeseries'].values.T\n",
    "    dataset = Data(ts, procnames=process_names, name=subject)\n",
    "    dataset._procnames = process_names  # type: ignore\n",
    "    # raise ValueError\n",
    "    datasets.append(dataset)\n",
    "\n",
    "calc = CalculatorFrame(datasets=datasets, subset='fast',\n",
    "                       name=f'Julia2018_{atlas}_{process_type}',\n",
    "                       names=[d.name for d in datasets])\n",
    "calc.compute()\n",
    "clear_output()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71ba167a1b745a89890d9ec71912745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spis = []\n",
    "for c in tqdm(calc.calculators.values[:, 0]):\n",
    "    feats = c.table\n",
    "    feats.index.name = 'process_1'\n",
    "    feats = feats.reset_index()\n",
    "    feats.columns.names = ['spi', 'process_2']\n",
    "    melted = pd.melt(feats, id_vars='process_1', var_name=['spi', 'process_2'], value_name='value')\n",
    "    melted['process'] = melted.apply(lambda x: set(x[['process_1', 'process_2']]), axis=1)\n",
    "    melted = melted.groupby('spi').apply(lambda x: x.drop_duplicates('process'))\n",
    "    # melted.dropna(subset=['value'], inplace=True)\n",
    "    melted['process'] = melted['process_1'] + '-' + melted['process_2']\n",
    "    melted.drop(columns=['spi', 'process_1', 'process_2'], inplace=True)\n",
    "    melted.reset_index(level=0, inplace=True)\n",
    "    melted.reset_index(drop=True, inplace=True)\n",
    "    melted = melted.assign(subject=c.name, label=c.name[:4])\n",
    "    spis.append(melted)\n",
    "\n",
    "spi_df = pd.concat(spis)\n",
    "spi_df_wide = spi_df.pivot_table(index=['subject', 'label', 'spi'], columns=['process'], values='value', aggfunc='mean').reset_index()\n",
    "spi_df_wide.to_csv(f'data/Julia2018/spis_{atlas}_{process_type}_fast.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPI Classifiers\n",
    "\n",
    "The following code receives one SPI as input and classifies it as AVGP or NVGP. Reported metrics are the validation accuracy (25% of the subjects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spi\n",
       "phase_multitaper_max_fs-1_fmin-0_fmax-0-5               0.720875\n",
       "sgc_parametric_mean_fs-1_fmin-1e-05_fmax-0-5_order-1    0.694125\n",
       "cov_GraphicalLassoCV                                    0.689875\n",
       "ddtf_multitaper_mean_fs-1_fmin-0_fmax-0-5               0.679625\n",
       "prec_LedoitWolf                                         0.673125\n",
       "                                                          ...   \n",
       "coint_johansen_trace_stat_order-1_ardiff-10             0.403875\n",
       "coint_johansen_trace_stat_order-0_ardiff-10             0.402750\n",
       "xcorr_mean_sig-True                                     0.384750\n",
       "pli_multitaper_max_fs-1_fmin-0_fmax-0-25                0.382750\n",
       "psi_wavelet_mean_fs-1_fmin-0-25_fmax-0-5_mean           0.382125\n",
       "Length: 209, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit, LeaveOneOut\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def score_spi(s):\n",
    "    print(s.name, '...', end=' ')\n",
    "    estimator = Pipeline([\n",
    "        # ('scaler', StandardScaler()),\n",
    "        # ('scale', MinMaxScaler(feature_range=(-1, 1))),\n",
    "        ('clf', SVC(kernel='linear'))\n",
    "        # ('clf', XGBClassifier())\n",
    "    ])\n",
    "    X = s.drop(columns=['subject', 'spi', 'label']).values\n",
    "    y = LabelEncoder().fit_transform(s['label'].values)\n",
    "    CV = StratifiedShuffleSplit(n_splits=1000, test_size=8)\n",
    "    # CV = LeaveOneOut()\n",
    "    score = cross_val_score(estimator, X, y, cv=CV, n_jobs=-1, scoring='accuracy')\n",
    "    print(f'acc={score.mean()}')\n",
    "    return score.mean()\n",
    "\n",
    "atlas = 'dosenbach2010'\n",
    "spi_df_wide = pd.read_csv(f'data/Julia2018/spis_{atlas}_{process_type}_fast.csv')\n",
    "s = spi_df_wide.groupby(['spi']).apply(lambda x: x.isna().sum().sum())\n",
    "\n",
    "null_spis = s[s>0].index\n",
    "spi_df_wide = spi_df_wide.query('spi not in @null_spis')\n",
    "scores = spi_df_wide.groupby(['spi']).apply(score_spi).sort_values(ascending=False)\n",
    "clear_output()\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
