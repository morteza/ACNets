{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/morteza/workspace/acnets/notebooks/2 MultiScale Classifier.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m \u001b[39mimport\u001b[39;00m tune\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtune\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msearch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhyperopt\u001b[39;00m \u001b[39mimport\u001b[39;00m HyperOptSearch\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtune\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m TuneSearchCV\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m stats\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestClassifier\n",
      "File \u001b[0;32m~/micromamba/envs/acnets/lib/python3.11/site-packages/ray/tune/sklearn.py:18\u001b[0m\n\u001b[1;32m     13\u001b[0m     tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n\u001b[1;32m     14\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m     15\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTune\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms Scikit-Learn bindings (tune-sklearn) is not installed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease run `pip install tune-sklearn`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(exc)()\u001b[39m.\u001b[39mwith_traceback(tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     19\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mTuneSearchCV\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTuneGridSearchCV\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/micromamba/envs/acnets/lib/python3.11/site-packages/ray/tune/sklearn.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m TuneGridSearchCV \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtune_sklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m TuneSearchCV, TuneGridSearchCV\n\u001b[1;32m     11\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     12\u001b[0m     \u001b[39m# Changed in 1.5.0 -- Raises an exception instead of returning None.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.tune.sklearn import TuneSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from src.acnets.pipeline import MultiScaleClassifier, Parcellation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "N_RUNS = 10      # 10 independent train/test runs\n",
    "TEST_SIZE = .25  # proportion of test subjects out of 32 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] label mapping: {'AVGP': 0, 'NVGP': 1}\n",
      "[DEBUG] overfit accuracy: 1.000\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Xy\n",
    "subjects = Parcellation(atlas_name='difumo_64_2mm').fit_transform(None).coords['subject'].values\n",
    "X = subjects.reshape(-1,1)                                  # subjects ids, shape: (n_subjects, 1)\n",
    "\n",
    "y_encoder = LabelEncoder()\n",
    "y = y_encoder.fit_transform([s[:4] for s in subjects])      # labels (AVGP=1 or NVGP=1), shape: (n_subjects,)\n",
    "y_mapping = dict(zip(y_encoder.classes_, y_encoder.transform(y_encoder.classes_)))\n",
    "\n",
    "# DEBUG (report label mapping)\n",
    "print('[DEBUG] label mapping:', y_mapping)\n",
    "\n",
    "# DEBUG (expected to overfit, i.e., accuracy is 1)\n",
    "overfit_score = MultiScaleClassifier().fit(X, y).score(X, y)\n",
    "print(f'[DEBUG] overfit accuracy: {overfit_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/morteza/workspace/acnets/notebooks/2 MultiScale Classifier.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ray\u001b[39m.\u001b[39mshutdown(); ray\u001b[39m.\u001b[39minit()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m xgb_param_space \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# 'atlas': ['dosenbach2010', 'gordon2014_2mm', 'difumo_64_2mm'],\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39matlas\u001b[39m\u001b[39m'\u001b[39m: tune\u001b[39m.\u001b[39mchoice([\u001b[39m'\u001b[39m\u001b[39mdosenbach2010\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# TODO 'clf__min_child_weight': tune.randint(1, 10),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m rfc_param_space \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m# 'clf': RandomForestClassifier(),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# 'atlas': tune.choice(['dosenbach2010', 'gordon2014_2mm', 'difumo_64_2mm']),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mclf__max_features\u001b[39m\u001b[39m'\u001b[39m: tune\u001b[39m.\u001b[39mchoice([\u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39msqrt\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ray' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "xgb_param_space = {\n",
    "    # 'atlas': ['dosenbach2010', 'gordon2014_2mm', 'difumo_64_2mm'],\n",
    "    'atlas': tune.choice(['dosenbach2010']),\n",
    "    'extract_h1_features': tune.grid_search([False]),\n",
    "    'extract_h2_features': tune.grid_search([True, False]),\n",
    "    'extract_h3_features': tune.grid_search([True]),\n",
    "    # 'clf__subsample': tune.choice([.5, .8, 1]),\n",
    "    'clf__n_estimators': tune.grid_search([100, 200]),\n",
    "    'clf__max_depth': tune.grid_search([2, 4, 6, 8]),\n",
    "    'clf__learning_rate': tune.grid_search([.1, .3]),\n",
    "    # 'clf__colsample_bytree': tune.uniform(0.1, 1.0),\n",
    "    # 'clf__colsample_bylevel': tune.uniform(0.1, 1.0),\n",
    "    # TODO 'clf__bagging_fraction': tune.uniform(0.01, 1.0),\n",
    "    # TODO 'clf__min_child_weight': tune.randint(1, 10),\n",
    "}\n",
    "\n",
    "rfc_param_space = {\n",
    "    # 'clf': RandomForestClassifier(),\n",
    "    # 'atlas': tune.choice(['dosenbach2010', 'gordon2014_2mm', 'difumo_64_2mm']),\n",
    "    'atlas': tune.choice(['dosenbach2010']),\n",
    "    'clf__n_estimators': tune.randint(100, 500),\n",
    "    'clf__max_depth': tune.randint(1, 8),\n",
    "    'clf__min_samples_split': tune.randint(2, 8),\n",
    "    'clf__min_samples_leaf': tune.randint(1, 5),\n",
    "    'clf__criterion': tune.choice(['gini', 'entropy']),\n",
    "    'clf__max_features': tune.choice([None, 'sqrt'])\n",
    "}\n",
    "\n",
    "svm_param_space = {\n",
    "    # 'clf': LinearSVC(max_iter=100000),\n",
    "    # 'atlas': tune.choice(['dosenbach2010', 'gordon2014_2mm', 'difumo_64_2mm']),\n",
    "    'atlas': tune.choice(['dosenbach2010']),\n",
    "    'clf__penalty': ['l1'],\n",
    "    'clf__dual': [False],\n",
    "    'clf__C': tune.choice([.01, .1, 1, 10, 100, 1000]),\n",
    "    # 'clf__kernel': ['linear','poly','rbf','sigmoid'],\n",
    "    # 'clf__gamma': tune.choice(['scale'])\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def eval_model(config,\n",
    "               X=X, y=y,\n",
    "               n_runs=3,\n",
    "               classifier=XGBClassifier(base_score=.5, objective='binary:logistic')):\n",
    "\n",
    "    val_scores = []\n",
    "    test_scores = []\n",
    "    for i in range(n_runs):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=TEST_SIZE, stratify=y)\n",
    "        cv = StratifiedShuffleSplit(n_splits=1, test_size=TEST_SIZE)\n",
    "\n",
    "        model = MultiScaleClassifier(classifier=classifier).set_params(**config)\n",
    "        cv = StratifiedShuffleSplit(n_splits=3, test_size=4)\n",
    "        score = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv).mean()\n",
    "\n",
    "        val_scores.append(score)\n",
    "        # TODO test_scores\n",
    "\n",
    "    return {'accuracy': np.mean(val_scores)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_param_space' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/morteza/workspace/acnets/notebooks/2 MultiScale Classifier.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#############################################\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# HPO\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#############################################\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m param_space \u001b[39m=\u001b[39m xgb_param_space\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ray\u001b[39m.\u001b[39mshutdown(); ray\u001b[39m.\u001b[39minit()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tuner \u001b[39m=\u001b[39m tune\u001b[39m.\u001b[39mTuner(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     eval_model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     param_space\u001b[39m=\u001b[39mparam_space,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/morteza/workspace/acnets/notebooks/2%20MultiScale%20Classifier.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb_param_space' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#############################################\n",
    "# HPO\n",
    "#############################################\n",
    "\n",
    "param_space = xgb_param_space\n",
    "\n",
    "ray.shutdown(); ray.init()\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    eval_model,\n",
    "    param_space=param_space,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=3,\n",
    "    )\n",
    ")\n",
    "\n",
    "# tuner = TuneSearchCV(\n",
    "#     model,\n",
    "#     HyperOptSearch.convert_search_space(config['params']),\n",
    "#     scoring='accuracy',\n",
    "#     cv=StratifiedShuffleSplit(n_splits=N_RUNS, test_size=TEST_SIZE),\n",
    "#     search_optimization='hyperopt',\n",
    "#     n_jobs=-1,\n",
    "#     refit=True,\n",
    "#     n_trials=10,\n",
    "#     verbose=2,)\n",
    "\n",
    "tuning_results = tuner.fit()\n",
    "ray.shutdown()\n",
    "\n",
    "\n",
    "# clear_output()\n",
    "print('[DEBUG] Best HPO score:',\n",
    "      tuner.get_results().get_best_result(metric='accuracy', mode='max').metrics['accuracy'])\n",
    "\n",
    "# create a tuned model using the best hyper-parameters\n",
    "best_params = tuner.get_results().get_best_result(metric='accuracy', mode='max').config\n",
    "tuned_model = MultiScaleClassifier(classifier=XGBClassifier()).set_params(**best_params)\n",
    "tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(tuned_model, X, y,\n",
    "                            cv=StratifiedShuffleSplit(n_splits=N_RUNS, test_size=TEST_SIZE),\n",
    "                            verbose=3, n_jobs=-1)\n",
    "\n",
    "# calculate 95% confidence interval\n",
    "bootstrap_ci = stats.bootstrap(cv_scores.reshape(1,-1), np.mean)\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(f'Test accuracy (mean ± std): {cv_scores.mean():.2f} ± {cv_scores.std():.2f}')\n",
    "print(bootstrap_ci.confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Permutation Feature Importance\n",
    "\n",
    "def get_importance(estimator, X_train, y_train, X_test, y_test, scoring='accuracy'):\n",
    "    \"\"\"Perform permutation importance analysis on a given estimator.\"\"\"\n",
    "    estimator.fit(X_train, y_train)\n",
    "    feature_names = estimator.get_feature_extractor().get_feature_names_out()\n",
    "    selected_feature_names = estimator[2:-1].get_feature_names_out(feature_names)\n",
    "\n",
    "    if 'xgb' in estimator.named_steps['clf'].__class__.__name__.lower():\n",
    "        # for xgb classifier we use its booster's get_score() method\n",
    "        booster = estimator.named_steps['clf'].get_booster()\n",
    "        booster.feature_names = selected_feature_names.tolist()\n",
    "        importance = booster.get_score(importance_type='weight', fmap='')\n",
    "    elif 'feature_importances_' in dir(estimator.named_steps['clf']):\n",
    "        # for some other classifiers we use their feature_importances_ attribute\n",
    "        importance = estimator.named_steps['clf'].feature_importances_\n",
    "    else:\n",
    "        # generic permutation importance\n",
    "        X_test_features = estimator.get_feature_extractor().transform(X_test)\n",
    "        feature_names = estimator.get_feature_extractor().get_feature_names_out()\n",
    "        importance = permutation_importance(estimator.get_classification_head(),\n",
    "                                         X_test_features,\n",
    "                                         y_test,\n",
    "                                         n_jobs=-1,\n",
    "                                         scoring=scoring)['importances_mean']\n",
    "        importance = dict(zip(feature_names, importance))\n",
    "\n",
    "    importance_df = pd.DataFrame([(k, v)\n",
    "                                  for k, v in importance.items()],\n",
    "                                 columns=['feature', 'importance'])\n",
    "    return importance_df\n",
    "\n",
    "\n",
    "# run permutation importance in parallel\n",
    "importances = Parallel(n_jobs=-1, verbose=2)(\n",
    "    delayed(get_importance)(\n",
    "        estimator = tuned_model,\n",
    "        X_train = X[train],\n",
    "        y_train = y[train],\n",
    "        X_test = X[test],\n",
    "        y_test = y[test])\n",
    "    for train, test in StratifiedShuffleSplit(n_splits=N_RUNS, test_size=TEST_SIZE).split(X, y)\n",
    ")\n",
    "\n",
    "# # convert importance scores to dataframe and sort\n",
    "\n",
    "importance_scores = pd.concat(importances, axis=0)\n",
    "\n",
    "# sort features by importance and select top-20 \n",
    "order = importance_scores.groupby('feature').mean().sort_values('importance', ascending=False)[:20].index\n",
    "\n",
    "# TODO plot H1, H2, H3 features importances\n",
    "\n",
    "sns.barplot(data=importance_scores,\n",
    "            order=order,  \n",
    "            x='importance',\n",
    "            y='feature',\n",
    "            errorbar=('ci', 95),\n",
    "            orient='h')\n",
    "\n",
    "plt.xlabel('Importance (average gain of tree-splits which use the feature)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
