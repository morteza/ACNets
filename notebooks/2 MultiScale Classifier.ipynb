{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiScale Classifier\n",
    "\n",
    "Sections:\n",
    "\n",
    "1. Data\n",
    "2. Hyper-parameter space\n",
    "3. HPO\n",
    "4. Cross-validation scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import ray\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import skexplain\n",
    "from skexplain.common.importance_utils import to_skexplain_importance\n",
    "\n",
    "from src.acnets.pipeline import MultiScaleClassifier, Parcellation\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 100      # 10 independent train/test runs\n",
    "TEST_SIZE = .25  # proportion of test subjects out of 32 subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xy\n",
    "subjects = Parcellation(atlas_name='difumo_64_2mm').fit_transform(None).coords['subject'].values\n",
    "X = subjects.reshape(-1,1)                                  # subjects ids, shape: (n_subjects, 1)\n",
    "\n",
    "y_encoder = LabelEncoder()\n",
    "y = y_encoder.fit_transform([s[:4] for s in subjects])      # labels (AVGP=1 or NVGP=1), shape: (n_subjects,)\n",
    "y_mapping = dict(zip(y_encoder.classes_, y_encoder.transform(y_encoder.classes_)))\n",
    "\n",
    "# DEBUG (report label mapping)\n",
    "print('[DEBUG] label mapping:', y_mapping)\n",
    "\n",
    "# DEBUG (expected to overfit, i.e., accuracy is 1)\n",
    "overfit_score = MultiScaleClassifier().fit(X, y).score(X, y)\n",
    "print(f'[DEBUG] overfit accuracy: {overfit_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    # 'atlas': ['dosenbach2010', 'gordon2014_2mm', 'difumo_64_2mm'],\n",
    "    'atlas': tune.choice(['dosenbach2010']),\n",
    "    'kind': tune.choice(['partial correlation']),\n",
    "    'extract_h1_features': tune.grid_search([True]),\n",
    "    'extract_h2_features': tune.grid_search([True]),\n",
    "    'extract_h3_features': tune.grid_search([True]),\n",
    "    # 'clf__subsample': tune.choice([.5, .8, 1]),\n",
    "    'clf__n_estimators': tune.grid_search([100, 200]),\n",
    "    'clf__max_depth': tune.grid_search([2, 4, 6, 8]),\n",
    "    'clf__learning_rate': tune.grid_search([.1, .3]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we define the objective function\n",
    "\n",
    "from ray import train\n",
    "\n",
    "def eval_multiscale_model(config, classifier, X, y, n_runs=10):\n",
    "\n",
    "    pipe = MultiScaleClassifier(classifier=classifier).set_params(**config)\n",
    "\n",
    "    for _ in range(n_runs):\n",
    "        # outer CV (for test set), and inner CV (for validation set)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, stratify=y)\n",
    "        inner_cv = StratifiedKFold(n_splits=8, shuffle=True)\n",
    "\n",
    "        # fit and score the validation set\n",
    "        val_score = cross_val_score(pipe, X_train, y_train, scoring='accuracy', cv=inner_cv).mean()\n",
    "\n",
    "        # test score (we only report this and do not use it during HPO)\n",
    "        test_score = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "        train.report({'val_accuracy': val_score, 'test_score': test_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep the hyper-parameter space and init the objective function\n",
    "output_name = f'models/multiscale_classifier-xgb-hpo.json'\n",
    "\n",
    "clf = XGBClassifier(base_score=.5, objective='binary:logistic')\n",
    "objective_func = partial(eval_multiscale_model, classifier=clf, X=X, y=y, n_runs=5)\n",
    "\n",
    "ray.shutdown(); ray.init()\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    objective_func,\n",
    "    param_space=param_space,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric='val_accuracy',\n",
    "        mode='max'\n",
    "    )\n",
    ")\n",
    "\n",
    "tuner.fit()\n",
    "ray.shutdown()\n",
    "\n",
    "clear_output()\n",
    "best_result = tuner.get_results().get_best_result(scope='avg')\n",
    "best_score = best_result.metrics['val_accuracy']\n",
    "best_params = best_result.config\n",
    "\n",
    "# store the best hyper-parameters\n",
    "with open(output_name, 'w') as f:\n",
    "    best_params['classifier'] = 'XGBClassifier'\n",
    "    json.dump(best_params, f, indent=2)\n",
    "    del best_params['classifier']  # TEMP: remove the classifier name\n",
    "\n",
    "# report best score and best model\n",
    "print('[DEBUG] Best HPO validation score:', best_score)\n",
    "MultiScaleClassifier(classifier=clf).set_params(**best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation accuracy and CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(base_score=.5, objective='binary:logistic')\n",
    "tuned_pipeline = MultiScaleClassifier(classifier=clf).set_params(**best_params)\n",
    "\n",
    "cv_scores = cross_val_score(tuned_pipeline, X, y,\n",
    "                            cv=StratifiedShuffleSplit(n_splits=N_RUNS, test_size=TEST_SIZE),\n",
    "                            verbose=3, n_jobs=-1)\n",
    "\n",
    "# Calculate 95% confidence interval\n",
    "bootstrap_ci = stats.bootstrap(cv_scores.reshape(1,-1), np.mean)\n",
    "\n",
    "# Report\n",
    "clear_output(wait=True)\n",
    "print(f'Test accuracy (mean ± std): {cv_scores.mean():.3f} ± {cv_scores.std():.3f}')\n",
    "print(bootstrap_ci.confidence_interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
