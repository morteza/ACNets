{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.tune.sklearn import TuneSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from src.acnets.pipeline import MultiScaleClassifier, Parcellation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 100      # 10 independent train/test runs\n",
    "TEST_SIZE = .25   # proportion of test subjects out of 32 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xy\n",
    "subjects = Parcellation(atlas_name='difumo_64_2mm').fit_transform(None).coords['subject'].values\n",
    "X = subjects.reshape(-1,1)                                  # subjects ids, shape: (n_subjects, 1)\n",
    "\n",
    "y_encoder = LabelEncoder()\n",
    "y = y_encoder.fit_transform([s[:4] for s in subjects])      # labels (AVGP=1 or NVGP=1), shape: (n_subjects,)\n",
    "y_mapping = dict(zip(y_encoder.classes_, y_encoder.transform(y_encoder.classes_)))\n",
    "\n",
    "# DEBUG (report label mapping)\n",
    "print('[DEBUG] label mapping:', y_mapping)\n",
    "\n",
    "# DEBUG (expected to overfit, i.e., accuracy is 1)\n",
    "overfit_score = MultiScaleClassifier().fit(X, y).score(X, y)\n",
    "print(f'[DEBUG] overfit accuracy: {overfit_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown(); ray.init()\n",
    "\n",
    "xgb_config = {\n",
    "    'clf': XGBClassifier(base_score=.5, objective='binary:logistic'),\n",
    "    'params': {\n",
    "        # 'atlas': ['dosenbach2010', 'gordon2014_2mm', 'difumo_64_2mm'],\n",
    "        'atlas': ['dosenbach2010'],\n",
    "        'extract_h1_features': tune.grid_search([False]),\n",
    "        'extract_h2_features': tune.grid_search([True, False]),\n",
    "        'extract_h3_features': tune.grid_search([True]),\n",
    "        # 'clf__subsample': tune.choice([.5, .8, 1]),\n",
    "        'clf__n_estimators': tune.grid_search([100, 200]),\n",
    "        'clf__max_depth': tune.grid_search([2, 4, 6, 8]),\n",
    "        'clf__learning_rate': tune.grid_search([.1, .3]),\n",
    "        # 'clf__colsample_bytree': tune.uniform(0.1, 1.0),\n",
    "        # 'clf__colsample_bylevel': tune.uniform(0.1, 1.0),\n",
    "        # TODO 'clf__bagging_fraction': tune.uniform(0.01, 1.0),\n",
    "        # TODO 'clf__min_child_weight': tune.randint(1, 10),\n",
    "    }\n",
    "}\n",
    "\n",
    "rfc_config = {\n",
    "    'clf': RandomForestClassifier(),\n",
    "    'params': {\n",
    "        # 'atlas': ['dosenbach2010', 'gordon2014_2mm', 'difumo_64_2mm'],\n",
    "        'atlas': ['dosenbach2010'],\n",
    "        'clf__n_estimators': tune.randint(100, 500),\n",
    "        'clf__max_depth': tune.randint(1, 8),\n",
    "        'clf__min_samples_split': tune.randint(2, 8),\n",
    "        'clf__min_samples_leaf': tune.randint(1, 5),\n",
    "        'clf__criterion': tune.choice(['gini', 'entropy']),\n",
    "        'clf__max_features': tune.choice([None, 'sqrt'])\n",
    "    }\n",
    "}\n",
    "\n",
    "svm_config = {\n",
    "    'clf': LinearSVC(max_iter=100000),\n",
    "    'params': {\n",
    "        # 'atlas': ['dosenbach2010', 'gordon2014_2mm', 'difumo_64_2mm'],\n",
    "        'atlas': ['dosenbach2010'],\n",
    "        'clf__penalty': ['l1'],\n",
    "        'clf__dual': [False],\n",
    "        'clf__C': tune.choice([.01, .1, 1, 10, 100, 1000]),\n",
    "        # 'clf__kernel': ['linear','poly','rbf','sigmoid'],\n",
    "        # 'clf__gamma': tune.choice(['scale'])\n",
    "    }\n",
    "}\n",
    "\n",
    "#############################################\n",
    "# HPO\n",
    "#############################################\n",
    "\n",
    "config = xgb_config\n",
    "param_space = config['params']\n",
    "model = MultiScaleClassifier(classifier=config['clf'])\n",
    "\n",
    "from ray.tune.sklearn import TuneGridSearchCV\n",
    "\n",
    "tuner = TuneGridSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedShuffleSplit(n_splits=N_RUNS, test_size=TEST_SIZE),\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    verbose=2,)\n",
    "\n",
    "# tuner = TuneSearchCV(\n",
    "#     model,\n",
    "#     HyperOptSearch.convert_search_space(config['params']),\n",
    "#     scoring='accuracy',\n",
    "#     cv=StratifiedShuffleSplit(n_splits=N_RUNS, test_size=TEST_SIZE),\n",
    "#     search_optimization='hyperopt',\n",
    "#     n_jobs=-1,\n",
    "#     refit=True,\n",
    "#     n_trials=10,\n",
    "#     verbose=2,)\n",
    "\n",
    "tuner.fit(X, y)\n",
    "ray.shutdown()\n",
    "\n",
    "clear_output()\n",
    "print('[DEBUG] Best HPO score:', tuner.best_score_)\n",
    "\n",
    "# create a tuned model using the best hyper-parameters\n",
    "tuned_model = MultiScaleClassifier(atlas=tuner.best_params_['atlas'],\n",
    "                                   classifier=config['clf']\n",
    "                                   ).set_params(**tuner.best_params_)\n",
    "\n",
    "tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(tuned_model, X, y,\n",
    "                            cv=StratifiedShuffleSplit(n_splits=N_RUNS, test_size=TEST_SIZE),\n",
    "                            verbose=3, n_jobs=-1)\n",
    "\n",
    "# calculate 95% confidence interval\n",
    "bootstrap_ci = stats.bootstrap(cv_scores.reshape(1,-1), np.mean)\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(f'Test accuracy (mean ± std): {cv_scores.mean():.2f} ± {cv_scores.std():.2f}')\n",
    "print(bootstrap_ci.confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation Feature Importance\n",
    "\n",
    "def get_importance(estimator, X_train, y_train, X_test, y_test, scoring='accuracy'):\n",
    "    \"\"\"Perform permutation importance analysis on a given estimator.\"\"\"\n",
    "    estimator.fit(X_train, y_train)\n",
    "    feature_names = estimator.get_feature_extractor().get_feature_names_out()\n",
    "    selected_feature_names = estimator[2:-1].get_feature_names_out(feature_names)\n",
    "\n",
    "    if 'xgb' in estimator.named_steps['clf'].__class__.__name__.lower():\n",
    "        # for xgb classifier we use its booster's get_score() method\n",
    "        booster = estimator.named_steps['clf'].get_booster()\n",
    "        booster.feature_names = selected_feature_names.tolist()\n",
    "        importance = booster.get_score(importance_type='weight', fmap='')\n",
    "    elif 'feature_importances_' in dir(estimator.named_steps['clf']):\n",
    "        # for some other classifiers we use their feature_importances_ attribute\n",
    "        importance = estimator.named_steps['clf'].feature_importances_\n",
    "    else:\n",
    "        # generic permutation importance\n",
    "        X_test_features = estimator.get_feature_extractor().transform(X_test)\n",
    "        feature_names = estimator.get_feature_extractor().get_feature_names_out()\n",
    "        importance = permutation_importance(estimator.get_classification_head(),\n",
    "                                         X_test_features,\n",
    "                                         y_test,\n",
    "                                         n_jobs=-1,\n",
    "                                         scoring=scoring)['importances_mean']\n",
    "        importance = dict(zip(feature_names, importance))\n",
    "\n",
    "    importance_df = pd.DataFrame([(k, v)\n",
    "                                  for k, v in importance.items()],\n",
    "                                 columns=['feature', 'importance'])\n",
    "    return importance_df\n",
    "\n",
    "\n",
    "# run permutation importance in parallel\n",
    "importances = Parallel(n_jobs=-1, verbose=2)(\n",
    "    delayed(get_importance)(\n",
    "        estimator = tuned_model,\n",
    "        X_train = X[train],\n",
    "        y_train = y[train],\n",
    "        X_test = X[test],\n",
    "        y_test = y[test])\n",
    "    for train, test in StratifiedShuffleSplit(n_splits=N_RUNS, test_size=TEST_SIZE).split(X, y)\n",
    ")\n",
    "\n",
    "# # convert importance scores to dataframe and sort\n",
    "\n",
    "importance_scores = pd.concat(importances, axis=0)\n",
    "\n",
    "# sort features by importance and select top-20 \n",
    "order = importance_scores.groupby('feature').mean().sort_values('importance', ascending=False)[:20].index\n",
    "\n",
    "sns.barplot(data=importance_scores,\n",
    "            order=order,  \n",
    "            x='importance',\n",
    "            y='feature',\n",
    "            errorbar=('ci', 95),\n",
    "            orient='h')\n",
    "\n",
    "plt.xlabel('Importance (average gain of tree-splits which use the feature)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
